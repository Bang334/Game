# üìä H∆Ø·ªöNG D·∫™N T√çNH BASE SCORE (Tr∆∞·ªõc khi Boost)

> **T√†i li·ªáu n√†y gi·∫£i th√≠ch chi ti·∫øt c√°ch h·ªá th·ªëng t√≠nh ƒëi·ªÉm BASE SCORE cho m·ªói game tr∆∞·ªõc khi √°p d·ª•ng Adaptive Boost.**

---

## üìå T·ªïng quan

**Base Score** l√† ƒëi·ªÉm g·ª£i √Ω ban ƒë·∫ßu ƒë∆∞·ª£c t√≠nh b·∫±ng c√°ch k·∫øt h·ª£p 4 ph∆∞∆°ng ph√°p AI:

```
Base Score = (SVD Score √ó W‚ÇÅ) + (Content Score √ó W‚ÇÇ) + (Demographic Score √ó W‚ÇÉ) + (Keyword Score √ó W‚ÇÑ)
```

Trong ƒë√≥ W‚ÇÅ, W‚ÇÇ, W‚ÇÉ, W‚ÇÑ l√† c√°c tr·ªçng s·ªë ƒë∆∞·ª£c ƒëi·ªÅu ch·ªânh ƒë·ªông d·ª±a tr√™n:
- Tr·∫°ng th√°i user (cold start hay kh√¥ng)
- C√≥ keyword t√¨m ki·∫øm hay kh√¥ng
- H√†nh vi user (behavior analysis)

---

## üéØ 4 Th√†nh ph·∫ßn c·ªßa Base Score

### 1Ô∏è‚É£ **SVD Score** (Collaborative Filtering)
> D·ª± ƒëo√°n rating c·ªßa user cho game d·ª±a tr√™n patterns t·ª´ users t∆∞∆°ng t·ª±

#### üìê Nguy√™n l√Ω ho·∫°t ƒë·ªông:

**SVD (Singular Value Decomposition)** l√† thu·∫≠t to√°n **Matrix Factorization** - ph√¢n t√≠ch ma tr·∫≠n t∆∞∆°ng t√°c user-game th√†nh 3 ma tr·∫≠n nh·ªè h∆°n ƒë·ªÉ t√¨m ra c√°c **hidden patterns** (latent factors).

**√ù t∆∞·ªüng c·ªët l√µi:**
- N·∫øu User A v√† User B th√≠ch nhi·ªÅu games gi·ªëng nhau ‚Üí h·ªç c√≥ "kh·∫©u v·ªã" t∆∞∆°ng t·ª±
- N·∫øu User A th√≠ch Game X, v√† User B c≈©ng c√≥ kh·∫©u v·ªã t∆∞∆°ng t·ª± ‚Üí User B c≈©ng s·∫Ω th√≠ch Game X

#### üî¢ C√°c b∆∞·ªõc t√≠nh to√°n chi ti·∫øt:

##### **B∆∞·ªõc 1: X√¢y d·ª±ng ma tr·∫≠n User-Game (Ratings Matrix)**

Ma tr·∫≠n n√†y l∆∞u tr·ªØ m·ª©c ƒë·ªô t∆∞∆°ng t√°c c·ªßa m·ªói user v·ªõi m·ªói game:

```
        Game 1  Game 2  Game 3  Game 4  Game 5
User 1    5.0     3.0     0       4.0     0
User 2    4.0     0       0       5.0     3.0
User 3    0       4.0     3.0     0       5.0
User 4    3.0     5.0     4.0     0       0
```

**C√°ch t√≠nh interaction weight:**

```python
# 1. Wishlist/Favorite (user ƒë√£ th√™m v√†o danh s√°ch y√™u th√≠ch)
if game_id in user.favorite_games:
    weight = 3.0  # Default rating cho wishlist

# 2. Purchased (user ƒë√£ mua v√† ƒë√°nh gi√°)
elif game_id in user.purchased_games:
    weight = user.purchased_games[game_id]  # Rating th·ª±c t·∫ø (1-5)

# 3. View History (user ƒë√£ xem)
elif game_id in user.view_history:
    view_count = user.view_history[game_id]
    weight = view_count * 0.5  # M·ªói l·∫ßn xem = 0.5 ƒëi·ªÉm
    weight = min(weight, 5.0)  # Gi·ªõi h·∫°n t·ªëi ƒëa 5.0

# 4. Kh√¥ng t∆∞∆°ng t√°c
else:
    weight = 0  # ƒê·ªÉ tr·ªëng (missing value)
```

**V√≠ d·ª• User 123:**
```python
User 123:
- Wishlist: [Game A, Game B]           ‚Üí [3.0, 3.0]
- Purchased: {Game C: 4, Game D: 5}    ‚Üí [4.0, 5.0]
- Views: {Game E: 3 l·∫ßn, Game F: 7 l·∫ßn} ‚Üí [1.5, 3.5]

# Ma tr·∫≠n cho User 123:
ratings_matrix[123] = [3.0, 3.0, 4.0, 5.0, 1.5, 3.5, 0, 0, ...]
```

---

##### **B∆∞·ªõc 2: SVD Decomposition (Ph√¢n t√≠ch ma tr·∫≠n)**

SVD ph√¢n t√°ch ma tr·∫≠n **R** (m users √ó n games) th√†nh 3 ma tr·∫≠n:

```
R ‚âà U √ó Œ£ √ó V·µÄ
```

Trong ƒë√≥:
- **U**: Ma tr·∫≠n User-Factor (m users √ó k factors)
  - M·ªói h√†ng = vector ƒë·∫∑c tr∆∞ng c·ªßa 1 user
  - V√≠ d·ª•: User 123 = [0.23, -0.15, 0.87, ...] (k factors)
  
- **Œ£**: Ma tr·∫≠n Singular Values (k √ó k)
  - Ma tr·∫≠n ƒë∆∞·ªùng ch√©o ch·ª©a c√°c gi√° tr·ªã singular (ƒëo "t·∫ßm quan tr·ªçng" c·ªßa m·ªói factor)
  
- **V·µÄ**: Ma tr·∫≠n Game-Factor (k factors √ó n games)
  - M·ªói c·ªôt = vector ƒë·∫∑c tr∆∞ng c·ªßa 1 game
  - V√≠ d·ª•: Game X = [0.45, 0.32, -0.18, ...] (k factors)

**Minh h·ªça:**

```
        [User Factors]    [Importance]   [Game Factors]
R   =        U         √ó       Œ£       √ó       V·µÄ

(m√ón)      (m√ók)            (k√ók)           (k√ón)

[5 3 ?]   [0.2 0.1]   [3.5  0 ]   [0.4 0.3 0.5]
[4 0 5] = [0.3 0.2] √ó [ 0  2.1] √ó [0.1 0.2 0.4]
[0 4 3]   [0.1 0.3]
```

**k l√† s·ªë factors (latent dimensions):**
- Th∆∞·ªùng ch·ªçn k = 50-200
- k nh·ªè ‚Üí model ƒë∆°n gi·∫£n, √≠t overfitting
- k l·ªõn ‚Üí model ph·ª©c t·∫°p, capture nhi·ªÅu patterns

---

##### **üéØ K l√† g√¨? V√† c√°ch ch·ªçn K t·ªëi ∆∞u**

###### **1. K (Number of Latent Factors) l√† g√¨?**

**K** l√† s·ªë chi·ªÅu ·∫©n (hidden dimensions) m√† SVD s·ª≠ d·ª•ng ƒë·ªÉ bi·ªÉu di·ªÖn user v√† game preferences.

**V√≠ d·ª• tr·ª±c quan:**

Thay v√¨ l∆∞u to√†n b·ªô ma tr·∫≠n ratings (c√≥ th·ªÉ r·∫•t l·ªõn v√† th∆∞a):
```
Ma tr·∫≠n R: 10,000 users √ó 50,000 games = 500 tri·ªáu gi√° tr·ªã
```

SVD n√©n th√†nh 3 ma tr·∫≠n nh·ªè h∆°n v·ªõi k factors:
```
U: 10,000 √ó k
Œ£: k √ó k
Vt: k √ó 50,000

T·ªïng: 10,000k + k¬≤ + 50,000k = 60,000k + k¬≤

N·∫øu k=100:
- Full matrix: 500,000,000 values
- SVD: 6,010,000 values ‚Üí Gi·∫£m 99%!
```

**K ƒë·∫°i di·ªán cho:**
- Factor 1: "Action games with good graphics"
- Factor 2: "Casual indie games"
- Factor 3: "Multiplayer competitive games"
- Factor 4: "Story-driven RPGs"
- ...
- Factor k: "Less important pattern"

---

###### **2. T√°c ƒë·ªông c·ªßa K ƒë·∫øn model**

**Quan h·ªá gi·ªØa K v√† ƒë·ªô ph·ª©c t·∫°p:**

```
K nh·ªè (10-30)
‚îú‚îÄ ‚úÖ Model ƒë∆°n gi·∫£n, generalize t·ªët
‚îú‚îÄ ‚úÖ Training nhanh
‚îú‚îÄ ‚úÖ √çt overfitting
‚îú‚îÄ ‚ö†Ô∏è B·ªè qua nhi·ªÅu patterns ph·ª©c t·∫°p
‚îî‚îÄ ‚ö†Ô∏è C√≥ th·ªÉ underfitting

K trung b√¨nh (50-150) ‚≠ê RECOMMENDED
‚îú‚îÄ ‚úÖ C√¢n b·∫±ng t·ªët
‚îú‚îÄ ‚úÖ Capture ƒë·ªß patterns quan tr·ªçng
‚îú‚îÄ ‚úÖ V·∫´n generalize t·ªët
‚îî‚îÄ ‚úÖ Ph√π h·ª£p v·ªõi h·∫ßu h·∫øt datasets

K l·ªõn (200-500)
‚îú‚îÄ ‚úÖ Capture m·ªçi patterns, k·ªÉ c·∫£ nh·ªè
‚îú‚îÄ ‚ö†Ô∏è Training ch·∫≠m
‚îú‚îÄ ‚ö†Ô∏è D·ªÖ overfitting (ghi nh·ªõ noise)
‚îî‚îÄ ‚ö†Ô∏è C·∫ßn nhi·ªÅu data
```

**Minh h·ªça v·ªõi v√≠ d·ª•:**

```python
# Dataset: 1000 users, 5000 games, 50,000 ratings

# K = 10 (qu√° nh·ªè)
Train RMSE: 0.95  # Kh√¥ng fit t·ªët data
Test RMSE:  0.98  # C≈©ng kh√¥ng t·ªët
‚Üí UNDERFITTING: Model qu√° ƒë∆°n gi·∫£n

# K = 100 (t·ªëi ∆∞u) ‚≠ê
Train RMSE: 0.72
Test RMSE:  0.76
‚Üí GOOD FIT: Generalize t·ªët

# K = 500 (qu√° l·ªõn)
Train RMSE: 0.45  # Fit r·∫•t t·ªët training data
Test RMSE:  1.12  # T·ªá tr√™n test data
‚Üí OVERFITTING: Ghi nh·ªõ noise
```

---

###### **3. C√°c ph∆∞∆°ng ph√°p ch·ªçn K**

**Ph∆∞∆°ng ph√°p 1: Cross-Validation (Khuy·∫øn ngh·ªã) ‚≠ê**

```python
from sklearn.model_selection import KFold
import numpy as np

def find_optimal_k(ratings_matrix, k_values=[20, 50, 100, 150, 200]):
    """
    T√¨m k t·ªëi ∆∞u b·∫±ng 5-fold cross-validation
    """
    kf = KFold(n_splits=5, shuffle=True, random_state=42)
    results = {}
    
    for k in k_values:
        rmse_scores = []
        
        for train_idx, test_idx in kf.split(ratings_matrix):
            # Split data
            train_data = ratings_matrix[train_idx]
            test_data = ratings_matrix[test_idx]
            
            # Train SVD
            U, sigma, Vt = svds(train_data, k=k)
            
            # Predict on test set
            predictions = U @ np.diag(sigma) @ Vt
            
            # Calculate RMSE
            rmse = np.sqrt(np.mean((test_data - predictions) ** 2))
            rmse_scores.append(rmse)
        
        # Average RMSE across folds
        results[k] = {
            'mean_rmse': np.mean(rmse_scores),
            'std_rmse': np.std(rmse_scores)
        }
        
        print(f"k={k}: RMSE = {results[k]['mean_rmse']:.4f} ¬± {results[k]['std_rmse']:.4f}")
    
    # Ch·ªçn k c√≥ RMSE th·∫•p nh·∫•t
    best_k = min(results, key=lambda k: results[k]['mean_rmse'])
    print(f"\nüéØ Best k: {best_k}")
    
    return best_k, results

# S·ª≠ d·ª•ng
best_k, cv_results = find_optimal_k(ratings_matrix)
```

**K·∫øt qu·∫£ v√≠ d·ª•:**
```
k=20:  RMSE = 0.9234 ¬± 0.0156
k=50:  RMSE = 0.8123 ¬± 0.0142
k=100: RMSE = 0.7645 ¬± 0.0128  ‚Üê Best!
k=150: RMSE = 0.7689 ¬± 0.0151
k=200: RMSE = 0.7823 ¬± 0.0198

üéØ Best k: 100
```

---

**Ph∆∞∆°ng ph√°p 2: Explained Variance**

```python
def analyze_variance(ratings_matrix, max_k=200):
    """
    Ph√¢n t√≠ch % variance explained b·ªüi c√°c factors
    """
    # Full SVD (l·∫•y t·∫•t c·∫£ factors)
    U, sigma, Vt = svds(ratings_matrix, k=min(max_k, min(ratings_matrix.shape)-1))
    
    # T√≠nh % variance explained
    total_variance = np.sum(sigma ** 2)
    explained_variance = []
    cumulative_variance = []
    
    cum_sum = 0
    for i, s in enumerate(sorted(sigma, reverse=True)):
        variance = (s ** 2) / total_variance * 100
        cum_sum += variance
        explained_variance.append(variance)
        cumulative_variance.append(cum_sum)
    
    # Plot
    import matplotlib.pyplot as plt
    
    plt.figure(figsize=(12, 5))
    
    # Subplot 1: Individual variance
    plt.subplot(1, 2, 1)
    plt.bar(range(1, len(explained_variance)+1), explained_variance)
    plt.xlabel('Factor')
    plt.ylabel('% Variance Explained')
    plt.title('Variance by Factor')
    
    # Subplot 2: Cumulative variance
    plt.subplot(1, 2, 2)
    plt.plot(range(1, len(cumulative_variance)+1), cumulative_variance)
    plt.axhline(y=80, color='r', linestyle='--', label='80% threshold')
    plt.axhline(y=90, color='g', linestyle='--', label='90% threshold')
    plt.xlabel('Number of Factors (k)')
    plt.ylabel('Cumulative % Variance')
    plt.title('Cumulative Variance Explained')
    plt.legend()
    
    plt.tight_layout()
    plt.show()
    
    # T√¨m k ƒë·ªÉ ƒë·∫°t 80% v√† 90% variance
    k_80 = next(i+1 for i, v in enumerate(cumulative_variance) if v >= 80)
    k_90 = next(i+1 for i, v in enumerate(cumulative_variance) if v >= 90)
    
    print(f"k for 80% variance: {k_80}")
    print(f"k for 90% variance: {k_90}")
    
    return k_80, k_90

# S·ª≠ d·ª•ng
k_80, k_90 = analyze_variance(ratings_matrix)
```

**K·∫øt qu·∫£ v√≠ d·ª•:**
```
Factor 1: 12.3% variance
Factor 2: 8.7% variance
Factor 3: 6.2% variance
...
Factor 67: 0.5% variance
...
Factor 123: 0.1% variance

k for 80% variance: 67  ‚Üê Ch·ªçn k n√†y n·∫øu mu·ªën hi·ªáu qu·∫£
k for 90% variance: 123 ‚Üê Ch·ªçn k n√†y n·∫øu mu·ªën ƒë·∫ßy ƒë·ªß h∆°n
```

**Rule of thumb:**
- Ch·ªçn k ƒë·ªÉ ƒë·∫°t **80-90% cumulative variance**
- N·∫øu k qu√° l·ªõn (>200), gi·ªØ nguy√™n 200

---

**Ph∆∞∆°ng ph√°p 3: Elbow Method**

```python
def elbow_method(ratings_matrix, k_range=range(10, 201, 10)):
    """
    V·∫Ω ƒë·ªì th·ªã RMSE vs K ƒë·ªÉ t√¨m "elbow point"
    """
    train_rmse = []
    test_rmse = []
    
    # Split train/test
    from sklearn.model_selection import train_test_split
    train_data, test_data = train_test_split(
        ratings_matrix, test_size=0.2, random_state=42
    )
    
    for k in k_range:
        # Train
        U, sigma, Vt = svds(train_data, k=k)
        
        # Evaluate
        train_pred = U @ np.diag(sigma) @ Vt
        train_rmse.append(np.sqrt(np.mean((train_data - train_pred) ** 2)))
        
        test_pred = U @ np.diag(sigma) @ Vt
        test_rmse.append(np.sqrt(np.mean((test_data - test_pred) ** 2)))
    
    # Plot
    import matplotlib.pyplot as plt
    plt.figure(figsize=(10, 6))
    plt.plot(k_range, train_rmse, 'o-', label='Train RMSE')
    plt.plot(k_range, test_rmse, 's-', label='Test RMSE')
    plt.xlabel('k (Number of Factors)')
    plt.ylabel('RMSE')
    plt.title('Elbow Method for Optimal k')
    plt.legend()
    plt.grid(True)
    plt.show()
    
    # T√¨m elbow point (ƒëi·ªÉm test RMSE b·∫Øt ƒë·∫ßu tƒÉng)
    min_idx = np.argmin(test_rmse)
    optimal_k = list(k_range)[min_idx]
    
    print(f"üéØ Optimal k: {optimal_k}")
    return optimal_k

# S·ª≠ d·ª•ng
optimal_k = elbow_method(ratings_matrix)
```

**ƒê·ªì th·ªã v√≠ d·ª•:**
```
RMSE
 1.2 |                              Test ‚óè‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚óè‚îÄ‚îÄ‚îÄ‚óè
     |                           ‚óè/              
 1.0 |                      ‚óè/                    
     |                  ‚óè/                        
 0.8 |          ‚óè‚îÄ‚îÄ‚îÄ‚óè/  ‚Üê Elbow (k‚âà100)          
     |      ‚óè/                                    
 0.6 | ‚óè‚îÄ‚îÄ‚óè  Train                               
     |_____________________________________________
       10   30   50  100  150  200  250  k

‚Üí Ch·ªçn k=100 (ƒëi·ªÉm test RMSE th·∫•p nh·∫•t tr∆∞·ªõc khi tƒÉng)
```

---

###### **4. Quy t·∫Øc ch·ªçn K d·ª±a tr√™n k√≠ch th∆∞·ªõc dataset**

**Rule of Thumb:**

```python
def estimate_k(n_users, n_games, n_ratings):
    """
    ∆Ø·ªõc l∆∞·ª£ng k ph√π h·ª£p d·ª±a tr√™n dataset size
    """
    # Sparsity
    sparsity = 1 - (n_ratings / (n_users * n_games))
    
    # Quy t·∫Øc c∆° b·∫£n
    if n_ratings < 10000:
        k = 20  # Dataset nh·ªè
    elif n_ratings < 100000:
        k = 50  # Dataset trung b√¨nh
    elif n_ratings < 1000000:
        k = 100  # Dataset l·ªõn
    else:
        k = 150  # Dataset r·∫•t l·ªõn
    
    # ƒêi·ªÅu ch·ªânh theo sparsity
    if sparsity > 0.99:  # R·∫•t th∆∞a (>99%)
        k = int(k * 0.7)  # Gi·∫£m k
    elif sparsity < 0.95:  # √çt th∆∞a h∆°n
        k = int(k * 1.3)  # TƒÉng k
    
    # Gi·ªõi h·∫°n
    k = max(10, min(k, 200))
    
    print(f"Dataset: {n_users} users, {n_games} games, {n_ratings} ratings")
    print(f"Sparsity: {sparsity*100:.2f}%")
    print(f"Recommended k: {k}")
    
    return k

# V√≠ d·ª•
k = estimate_k(n_users=5000, n_games=10000, n_ratings=250000)
# Output:
# Dataset: 5000 users, 10000 games, 250000 ratings
# Sparsity: 99.50%
# Recommended k: 70
```

**B·∫£ng tham kh·∫£o:**

| Dataset Size | Sparsity | Recommended k | V√≠ d·ª• |
|--------------|----------|---------------|-------|
| < 10K ratings | > 99.5% | **20-30** | Startup m·ªõi |
| 10K - 100K | 99-99.5% | **40-60** | Small business |
| 100K - 1M | 98-99% | **80-120** | Medium platform |
| 1M - 10M | 95-98% | **120-180** | Large platform (Netflix) |
| > 10M | < 95% | **150-200** | Very large (YouTube) |

---

###### **5. Trade-offs khi ch·ªçn K**

| Y·∫øu t·ªë | K nh·ªè (20-50) | K trung b√¨nh (80-120) ‚≠ê | K l·ªõn (150-200) |
|--------|---------------|-------------------------|-----------------|
| **Training time** | ‚ö° R·∫•t nhanh (1-2 ph√∫t) | ‚ö° Nhanh (5-10 ph√∫t) | üêå Ch·∫≠m (20-30 ph√∫t) |
| **Memory usage** | üíæ Th·∫•p (100 MB) | üíæ Trung b√¨nh (500 MB) | üíæ Cao (2 GB) |
| **Accuracy** | ‚ö†Ô∏è Th·∫•p (RMSE ~0.9) | ‚úÖ Cao (RMSE ~0.75) | ‚úÖ R·∫•t cao (RMSE ~0.72) |
| **Overfitting risk** | ‚úÖ Th·∫•p | ‚úÖ Th·∫•p | ‚ö†Ô∏è Cao |
| **Generalization** | ‚úÖ T·ªët | ‚úÖ R·∫•t t·ªët | ‚ö†Ô∏è C√≥ th·ªÉ t·ªá |
| **Cold start handling** | ‚úÖ T·ªët | ‚úÖ Kh√° t·ªët | ‚ö†Ô∏è T·ªá h∆°n |

**Khuy·∫øn ngh·ªã:**
```
üéØ Start with k=100
   ‚Üì
   Test v·ªõi cross-validation
   ‚Üì
   ‚îú‚îÄ RMSE t·ªët ‚Üí Keep k=100
   ‚îú‚îÄ Underfitting ‚Üí TƒÉng k l√™n 150-200
   ‚îî‚îÄ Overfitting ‚Üí Gi·∫£m k xu·ªëng 50-80
```

---

###### **6. Code t·ªïng h·ª£p: T·ª± ƒë·ªông ch·ªçn k t·ªëi ∆∞u**

```python
import numpy as np
from scipy.sparse.linalg import svds
from sklearn.model_selection import train_test_split

def auto_select_k(ratings_matrix, k_candidates=[50, 80, 100, 120, 150]):
    """
    T·ª± ƒë·ªông ch·ªçn k t·ªëi ∆∞u b·∫±ng validation set
    """
    print("üîç Finding optimal k...")
    print("=" * 60)
    
    # Split data: 70% train, 15% validation, 15% test
    train_val, test = train_test_split(ratings_matrix, test_size=0.15, random_state=42)
    train, val = train_test_split(train_val, test_size=0.176, random_state=42)  # 0.176 ‚âà 15/85
    
    best_k = None
    best_rmse = float('inf')
    results = []
    
    for k in k_candidates:
        # Train SVD
        U, sigma, Vt = svds(train, k=k)
        
        # Predict on validation
        val_pred = U @ np.diag(sigma) @ Vt
        val_rmse = np.sqrt(np.mean((val - val_pred) ** 2))
        
        # Also compute train RMSE to check overfitting
        train_pred = U @ np.diag(sigma) @ Vt
        train_rmse = np.sqrt(np.mean((train - train_pred) ** 2))
        
        results.append({
            'k': k,
            'train_rmse': train_rmse,
            'val_rmse': val_rmse,
            'overfitting': val_rmse - train_rmse
        })
        
        print(f"k={k:3d} | Train RMSE: {train_rmse:.4f} | Val RMSE: {val_rmse:.4f} | Gap: {val_rmse-train_rmse:.4f}")
        
        if val_rmse < best_rmse:
            best_rmse = val_rmse
            best_k = k
    
    print("=" * 60)
    print(f"üéØ Best k: {best_k} (Val RMSE: {best_rmse:.4f})")
    
    # Final evaluation on test set
    U, sigma, Vt = svds(train_val, k=best_k)
    test_pred = U @ np.diag(sigma) @ Vt
    test_rmse = np.sqrt(np.mean((test - test_pred) ** 2))
    
    print(f"üìä Test RMSE with k={best_k}: {test_rmse:.4f}")
    
    return best_k, results

# S·ª≠ d·ª•ng
best_k, results = auto_select_k(ratings_matrix)
```

**Output v√≠ d·ª•:**
```
üîç Finding optimal k...
============================================================
k= 50 | Train RMSE: 0.8234 | Val RMSE: 0.8567 | Gap: 0.0333
k= 80 | Train RMSE: 0.7756 | Val RMSE: 0.7989 | Gap: 0.0233
k=100 | Train RMSE: 0.7423 | Val RMSE: 0.7645 | Gap: 0.0222 ‚Üê Best
k=120 | Train RMSE: 0.7312 | Val RMSE: 0.7698 | Gap: 0.0386
k=150 | Train RMSE: 0.7089 | Val RMSE: 0.7823 | Gap: 0.0734 ‚Üê Overfitting!
============================================================
üéØ Best k: 100 (Val RMSE: 0.7645)
üìä Test RMSE with k=100: 0.7701
```

---

###### **7. T√≥m t·∫Øt: Checklist ch·ªçn K**

‚úÖ **Quick Start (kh√¥ng c√≥ th·ªùi gian tune):**
```python
k = 100  # Default an to√†n cho h·∫ßu h·∫øt tr∆∞·ªùng h·ª£p
```

‚úÖ **C√≥ th·ªùi gian tune (khuy·∫øn ngh·ªã):**
```python
# 1. Estimate d·ª±a tr√™n dataset
k_estimate = estimate_k(n_users, n_games, n_ratings)

# 2. Cross-validation
k_optimal = auto_select_k(ratings_matrix, 
                          k_candidates=[k_estimate-20, k_estimate, k_estimate+20])

# 3. Validate
# - Check train/val RMSE gap < 0.05 (kh√¥ng overfitting)
# - Check test RMSE acceptable
```

‚úÖ **Production:**
```python
# Monitor v√† re-tune k ƒë·ªãnh k·ª≥ (3-6 th√°ng)
# Khi dataset tƒÉng ‚Üí c√≥ th·ªÉ tƒÉng k
```

---

##### **üî¨ Chi ti·∫øt: C√°ch t√≠nh ma tr·∫≠n U, Œ£, V·µÄ**

**SVD l√† thu·∫≠t to√°n to√°n h·ªçc thu·∫ßn t√∫y**, kh√¥ng c·∫ßn training nh∆∞ Neural Networks. C√°c b∆∞·ªõc t√≠nh:

###### **1. Thu·∫≠t to√°n SVD (Linear Algebra)**

```python
import numpy as np
from scipy.sparse.linalg import svds

# Ma tr·∫≠n ratings (m users √ó n games)
R = np.array([
    [5, 3, 0, 4, 0],  # User 1
    [4, 0, 0, 5, 3],  # User 2
    [0, 4, 3, 0, 5],  # User 3
    [3, 5, 4, 0, 0],  # User 4
])

# Th·ª±c hi·ªán SVD v·ªõi k factors
k = 2  # S·ªë latent factors
U, sigma, Vt = svds(R, k=k)

# K·∫øt qu·∫£:
# U: (4 users √ó 2 factors)
# sigma: (2,) - array 1D ch·ª©a singular values
# Vt: (2 factors √ó 5 games)
```

**Output v√≠ d·ª•:**
```python
U = [
    [-0.58, -0.15],  # User 1 preferences
    [-0.45, -0.32],  # User 2 preferences
    [-0.41,  0.61],  # User 3 preferences
    [-0.54,  0.70],  # User 4 preferences
]

sigma = [9.72, 5.22]  # Importance of factors

Vt = [
    [-0.46, -0.38, -0.30, -0.43, -0.32],  # Factor 1
    [ 0.14, -0.52, -0.72,  0.19, -0.39],  # Factor 2
]
```

###### **2. Gi·∫£i th√≠ch t·ª´ng ma tr·∫≠n**

**Ma tr·∫≠n U (User-Factor):**

M·ªói h√†ng ƒë·∫°i di·ªán cho "kh·∫©u v·ªã ·∫©n" c·ªßa user:

```
User 1: [-0.58, -0.15]
         ‚Üì       ‚Üì
    Factor 1  Factor 2
    
Gi·∫£i th√≠ch:
- Factor 1 = -0.58 (cao): User th√≠ch "action games v·ªõi ƒë·ªì h·ªça ƒë·∫πp"
- Factor 2 = -0.15 (th·∫•p): User √≠t quan t√¢m "indie games"
```

**Ma tr·∫≠n Œ£ (Singular Values):**

ƒêo "t·∫ßm quan tr·ªçng" c·ªßa m·ªói factor:

```
sigma = [9.72, 5.22]
         ‚Üì     ‚Üì
    Factor 1: Quan tr·ªçng nh·∫•t (gi·∫£i th√≠ch 65% variance)
    Factor 2: √çt quan tr·ªçng h∆°n (gi·∫£i th√≠ch 35% variance)
```

C√¥ng th·ª©c t√≠nh % variance explained:
```python
variance_explained = sigma[i]¬≤ / sum(sigma¬≤)
# Factor 1: 9.72¬≤ / (9.72¬≤ + 5.22¬≤) = 94.4 / 121.7 = 77.6%
# Factor 2: 5.22¬≤ / (9.72¬≤ + 5.22¬≤) = 27.2 / 121.7 = 22.4%
```

**Ma tr·∫≠n V·µÄ (Game-Factor):**

M·ªói c·ªôt ƒë·∫°i di·ªán cho "ƒë·∫∑c tr∆∞ng ·∫©n" c·ªßa game:

```
Game 1: [-0.46, 0.14]
          ‚Üì      ‚Üì
     Factor 1  Factor 2

Gi·∫£i th√≠ch:
- Factor 1 = -0.46: Game c√≥ "action + graphics" cao
- Factor 2 = 0.14: Game c√≥ ch√∫t "indie style"
```

###### **3. Qu√° tr√¨nh t√≠nh to√°n b√™n trong SVD**

SVD c√≥ th·ªÉ ƒë∆∞·ª£c t√≠nh b·∫±ng **2 c√°ch**:

---

##### **C√ÅCH 1: Thu·∫≠t to√°n to√°n h·ªçc ch√≠nh x√°c (Mathematical SVD)**

ƒê√¢y l√† c√°ch SVD "th·∫≠t" trong Linear Algebra, t√≠nh **exact decomposition**.

**üî¢ C√°c b∆∞·ªõc to√°n h·ªçc:**

**B∆∞·ªõc 1: T√≠nh ma tr·∫≠n R·µÄ√óR (Gram matrix)**

```
A = R·µÄ √ó R
```

V·ªõi R l√† ma tr·∫≠n (m √ó n):
```python
# R: 4 users √ó 5 games
R = [[5, 3, 0, 4, 0],
     [4, 0, 0, 5, 3],
     [0, 4, 3, 0, 5],
     [3, 5, 4, 0, 0]]

# R·µÄ: 5 games √ó 4 users (transpose)
R·µÄ = [[5, 4, 0, 3],
      [3, 0, 4, 5],
      [0, 0, 3, 4],
      [4, 5, 0, 0],
      [0, 3, 5, 0]]

# A = R·µÄ √ó R (5√ó4 √ó 4√ó5 = 5√ó5)
A = [[50, 27, 12, 35,  9],
     [27, 50, 20,  0, 25],
     [12, 20, 25,  0, 20],
     [35,  0,  0, 41,  0],
     [ 9, 25, 20,  0, 34]]
```

**B∆∞·ªõc 2: T√¨m eigenvalues v√† eigenvectors c·ªßa A**

Ma tr·∫≠n A l√† **symmetric positive semi-definite** ‚Üí c√≥ eigenvalues th·ª±c, eigenvectors tr·ª±c giao.

```
A √ó v = Œª √ó v
```

Gi·∫£i ph∆∞∆°ng tr√¨nh ƒë·∫∑c tr∆∞ng:
```
det(A - ŒªI) = 0
```

**Chi ti·∫øt t√≠nh to√°n:**

```python
# C√¥ng th·ª©c: (A - ŒªI) √ó v = 0

# 1. T√¨m eigenvalues Œª b·∫±ng c√°ch gi·∫£i:
|A - ŒªI| = 0

# V√≠ d·ª• v·ªõi ma tr·∫≠n 2√ó2 ƒë∆°n gi·∫£n:
A = [[5, 2],
     [2, 3]]

# Det:
|5-Œª   2  | = (5-Œª)(3-Œª) - 4 = 0
| 2   3-Œª | 

Œª¬≤ - 8Œª + 11 = 0
Œª‚ÇÅ = 6.24, Œª‚ÇÇ = 1.76

# 2. V·ªõi m·ªói Œª, t√¨m eigenvector v:
(A - ŒªI) √ó v = 0

# V·ªõi Œª‚ÇÅ = 6.24:
[[5-6.24,  2    ], [v‚ÇÅ] = [0]
 [2,      3-6.24]] [v‚ÇÇ]   [0]

[[-1.24,  2   ], [v‚ÇÅ] = [0]
 [ 2,    -3.24]] [v‚ÇÇ]   [0]

# Gi·∫£i h·ªá:
-1.24v‚ÇÅ + 2v‚ÇÇ = 0
v‚ÇÇ = 0.62v‚ÇÅ

# Chu·∫©n h√≥a (||v|| = 1):
v‚ÇÅ¬≤ + v‚ÇÇ¬≤ = 1
v‚ÇÅ¬≤ + (0.62v‚ÇÅ)¬≤ = 1
v‚ÇÅ = 0.85, v‚ÇÇ = 0.53

# Eigenvector 1: [0.85, 0.53]
```

V·ªõi ma tr·∫≠n 5√ó5 ·ªü tr√™n, ta c√≥:
```python
# Eigenvalues (sorted descending):
Œª‚ÇÅ = 121.5
Œª‚ÇÇ = 45.8
Œª‚ÇÉ = 23.1
Œª‚ÇÑ = 8.6
Œª‚ÇÖ = 1.0

# Eigenvectors (5√ó5 matrix V):
V = [[ 0.52, -0.31,  0.68, -0.38,  0.15],
     [ 0.48, -0.45, -0.39,  0.61,  0.17],
     [ 0.39,  0.28, -0.58, -0.64, -0.12],
     [ 0.45,  0.71,  0.11,  0.15, -0.52],
     [ 0.38, -0.34,  0.23,  0.32,  0.81]]
```

**B∆∞·ªõc 3: T√≠nh singular values (Œ£)**

```
œÉ·µ¢ = ‚àöŒª·µ¢
```

```python
# T·ª´ eigenvalues ‚Üí singular values
œÉ‚ÇÅ = ‚àö121.5 = 11.02
œÉ‚ÇÇ = ‚àö45.8  = 6.77
œÉ‚ÇÉ = ‚àö23.1  = 4.81
œÉ‚ÇÑ = ‚àö8.6   = 2.93
œÉ‚ÇÖ = ‚àö1.0   = 1.00

# Ma tr·∫≠n Œ£ (diagonal):
Œ£ = [[11.02,  0,     0,     0,     0   ],
     [ 0,     6.77,  0,     0,     0   ],
     [ 0,     0,     4.81,  0,     0   ],
     [ 0,     0,     0,     2.93,  0   ],
     [ 0,     0,     0,     0,     1.00]]
```

**B∆∞·ªõc 4: T√≠nh ma tr·∫≠n V·µÄ**

Ma tr·∫≠n V t·ª´ eigenvectors ch√≠nh l√† V·µÄ (sau khi truncate k factors):

```python
# L·∫•y k=3 factors quan tr·ªçng nh·∫•t
V·µÄ = V[:k, :]  # (3 √ó 5)

V·µÄ = [[ 0.52, -0.31,  0.68, -0.38,  0.15],
      [ 0.48, -0.45, -0.39,  0.61,  0.17],
      [ 0.39,  0.28, -0.58, -0.64, -0.12]]
```

**B∆∞·ªõc 5: T√≠nh ma tr·∫≠n U**

```
U = R √ó V √ó Œ£‚Åª¬π
```

```python
# V: eigenvectors (5√ó3)
# Œ£‚Åª¬π: inverse singular values (3√ó3)
Œ£_inv = [[1/11.02,  0,        0      ],
         [0,        1/6.77,   0      ],
         [0,        0,        1/4.81 ]]

# U = R √ó V √ó Œ£‚Åª¬π
U = [[5, 3, 0, 4, 0],     [[ 0.52,  0.48,  0.39],     [[0.091,  0,      0    ],
     [4, 0, 0, 5, 3],   √ó   [-0.31, -0.45,  0.28],  √ó   [0,      0.148,  0    ],
     [0, 4, 3, 0, 5],       [ 0.68, -0.39, -0.58],      [0,      0,      0.208]]
     [3, 5, 4, 0, 0]]       [-0.38,  0.61, -0.64],
                            [ 0.15,  0.17, -0.12]]

# K·∫øt qu·∫£ (4 users √ó 3 factors):
U = [[-0.58, -0.15,  0.34],
     [-0.45, -0.32, -0.61],
     [-0.41,  0.61,  0.58],
     [-0.54,  0.70, -0.23]]
```

**T√≥m t·∫Øt c√¥ng th·ª©c:**

```
1. A = R·µÄ √ó R                    (Gram matrix)
2. A √ó v = Œª √ó v                 (Eigenvalue problem)
3. œÉ·µ¢ = ‚àöŒª·µ¢                      (Singular values)
4. V·µÄ = eigenvectors(A)·µÄ        (Right singular vectors)
5. U = R √ó V √ó Œ£‚Åª¬π              (Left singular vectors)
```

---

##### **C√ÅCH 2: Alternating Least Squares (ALS) - Approximate SVD**

ƒê√¢y l√† ph∆∞∆°ng ph√°p **iterative approximation**, th∆∞·ªùng d√πng cho ma tr·∫≠n l·ªõn v√† sparse.

**üîÑ √ù t∆∞·ªüng:**

Thay v√¨ gi·∫£i exact eigenvalue problem (t·ªën k√©m v·ªõi ma tr·∫≠n l·ªõn), ta:
1. Kh·ªüi t·∫°o U, Œ£, Vt ng·∫´u nhi√™n
2. L·∫∑p l·∫°i: fix 2 ma tr·∫≠n, t·ªëi ∆∞u 1 ma tr·∫≠n
3. D·ª´ng khi error ƒë·ªß nh·ªè

**B∆∞·ªõc 1: Kh·ªüi t·∫°o ng·∫´u nhi√™n**

```python
import numpy as np

# Ma tr·∫≠n R: m users √ó n games
m, n = 4, 5
k = 3  # Number of factors

# Random initialization
np.random.seed(42)
U = np.random.randn(m, k) * 0.1   # (4√ó3)
sigma = np.ones(k)                 # (3,)
Vt = np.random.randn(k, n) * 0.1  # (3√ó5)

# V√≠ d·ª•:
U = [[ 0.05,  0.04, -0.02],
     [ 0.09,  0.02,  0.05],
     [-0.01,  0.04,  0.03],
     [ 0.08, -0.03,  0.01]]

Vt = [[ 0.04,  0.08, -0.05,  0.02,  0.06],
      [-0.03,  0.02,  0.07, -0.04,  0.01],
      [ 0.06, -0.01,  0.03,  0.05, -0.02]]
```

**B∆∞·ªõc 2: Alternating optimization**

L·∫∑p l·∫°i cho ƒë·∫øn khi h·ªôi t·ª•:

```python
for iteration in range(max_iterations):
    # === Sub-step A: Fix Vt v√† Œ£, t·ªëi ∆∞u U ===
    for i in range(m):  # M·ªói user
        # Minimize: ||R·µ¢ - u·µ¢ @ Œ£ @ Vt||¬≤
        # 
        # Gi·∫£i: u·µ¢ = R·µ¢ @ Vt.T @ Œ£‚Åª¬π @ (Vt @ Vt.T + ŒªI)‚Åª¬π
        
        # 1. L·∫•y ratings c·ªßa user i
        Ri = R[i, :]  # (1√ó5)
        
        # 2. T√≠nh A = Vt @ Vt.T + ŒªI
        A = Vt @ Vt.T + lambda_reg * np.eye(k)
        # A shape: (k√ók)
        
        # 3. T√≠nh b = Ri @ Vt.T @ diag(sigma)
        b = Ri @ Vt.T @ np.diag(sigma)
        # b shape: (1√ók)
        
        # 4. Gi·∫£i h·ªá: A @ ui = b
        U[i, :] = np.linalg.solve(A, b)
    
    # === Sub-step B: Fix U v√† Œ£, t·ªëi ∆∞u Vt ===
    for j in range(n):  # M·ªói game
        # Minimize: ||R‚±º - U @ Œ£ @ vt‚±º||¬≤
        
        # 1. L·∫•y ratings c·ªßa game j
        Rj = R[:, j]  # (m√ó1)
        
        # 2. T√≠nh A = U.T @ U @ diag(sigma¬≤) + ŒªI
        A = U.T @ U @ np.diag(sigma**2) + lambda_reg * np.eye(k)
        
        # 3. T√≠nh b = U.T @ diag(sigma) @ Rj
        b = U.T @ np.diag(sigma) @ Rj
        
        # 4. Gi·∫£i h·ªá: A @ vtj = b
        Vt[:, j] = np.linalg.solve(A, b)
    
    # === Sub-step C: Fix U v√† Vt, t·ªëi ∆∞u Œ£ ===
    for f in range(k):  # M·ªói factor
        # T√≠nh optimal sigma[f]
        numerator = 0
        denominator = 0
        
        for i in range(m):
            for j in range(n):
                if R[i, j] != 0:  # Ch·ªâ t√≠nh v·ªõi known ratings
                    # Predicted contribution c·ªßa factor f
                    pred_f = U[i, f] * Vt[f, j]
                    
                    # Residual (kh√¥ng t√≠nh factor f)
                    residual = R[i, j]
                    for f2 in range(k):
                        if f2 != f:
                            residual -= sigma[f2] * U[i, f2] * Vt[f2, j]
                    
                    numerator += pred_f * residual
                    denominator += pred_f ** 2
        
        sigma[f] = numerator / (denominator + 1e-10)
    
    # === T√≠nh error ƒë·ªÉ check convergence ===
    R_pred = U @ np.diag(sigma) @ Vt
    error = np.sqrt(np.mean((R - R_pred) ** 2))
    
    print(f"Iteration {iteration}: RMSE = {error:.4f}")
    
    # Ki·ªÉm tra h·ªôi t·ª•
    if iteration > 0 and abs(prev_error - error) < threshold:
        print(f"Converged after {iteration} iterations")
        break
    
    prev_error = error
```

**Minh h·ªça chi ti·∫øt 1 iteration:**

**Iteration 1:**

```python
# Initial (random):
U = [[ 0.05,  0.04, -0.02],
     [ 0.09,  0.02,  0.05],
     [-0.01,  0.04,  0.03],
     [ 0.08, -0.03,  0.01]]

sigma = [1.0, 1.0, 1.0]

Vt = [[ 0.04,  0.08, -0.05,  0.02,  0.06],
      [-0.03,  0.02,  0.07, -0.04,  0.01],
      [ 0.06, -0.01,  0.03,  0.05, -0.02]]

# Predicted:
R_pred = U @ diag(sigma) @ Vt
R_pred = [[0.01, 0.01, 0.00, ...],  # R·∫•t sai!
          [0.00, 0.01, 0.01, ...],
          ...]

RMSE = 3.47  # Cao
```

**Update U (user 0):**

```python
# User 0: R[0] = [5, 3, 0, 4, 0]

# A = Vt @ Vt.T + 0.01*I
A = [[0.014, -0.001,  0.003],
     [-0.001, 0.006,  -0.002],
     [ 0.003, -0.002, 0.010]]

# b = R[0] @ Vt.T @ diag(sigma)
b = [5, 3, 0, 4, 0] @ Vt.T @ [1, 1, 1]
b = [0.46, 0.18, 0.31]

# Solve: A @ u = b
U[0] = [34.12, 15.67, 28.43]  # Gi√° tr·ªã m·ªõi!
```

**Sau nhi·ªÅu iterations:**

```python
# Iteration 50 (converged):
U = [[-0.58, -0.15,  0.34],
     [-0.45, -0.32, -0.61],
     [-0.41,  0.61,  0.58],
     [-0.54,  0.70, -0.23]]

sigma = [11.02, 6.77, 4.81]

Vt = [[ 0.52, -0.31,  0.68, -0.38,  0.15],
      [ 0.48, -0.45, -0.39,  0.61,  0.17],
      [ 0.39,  0.28, -0.58, -0.64, -0.12]]

RMSE = 0.021  # R·∫•t nh·ªè ‚Üí H·ªôi t·ª•!
```

**T√≥m t·∫Øt ALS:**

```
1. Initialize: U, Œ£, Vt ~ random
2. Repeat until convergence:
   a. Fix Vt, Œ£ ‚Üí Optimize U (solve least squares for each user)
   b. Fix U, Œ£ ‚Üí Optimize Vt (solve least squares for each game)
   c. Fix U, Vt ‚Üí Optimize Œ£ (closed-form update)
3. Check RMSE ‚Üí stop if change < threshold
```

---

##### **So s√°nh 2 c√°ch:**

| Ti√™u ch√≠ | Mathematical SVD | ALS Approximate |
|----------|------------------|-----------------|
| **Ch√≠nh x√°c** | ‚úÖ Exact decomposition | ‚ö†Ô∏è Approximate |
| **T·ªëc ƒë·ªô** | üêå Ch·∫≠m (O(mn¬≤) ho·∫∑c O(m¬≤n)) | ‚ö° Nhanh h∆°n v·ªõi sparse matrix |
| **Ma tr·∫≠n l·ªõn** | ‚ö†Ô∏è Kh√¥ng kh·∫£ thi (10K√ó10K+) | ‚úÖ X·ª≠ l√Ω ƒë∆∞·ª£c (1M√ó1M+) |
| **Sparse matrix** | ‚ö†Ô∏è Ph·∫£i fill 0s | ‚úÖ Ch·ªâ t√≠nh known ratings |
| **Regularization** | ‚ùå Kh√¥ng c√≥ | ‚úÖ C√≥ Œª ƒë·ªÉ tr√°nh overfitting |
| **Th∆∞ vi·ªán** | `numpy.linalg.svd` | `scipy.sparse.linalg.svds` |

**Khi n√†o d√πng c√°ch n√†o?**

```
Mathematical SVD:
- Ma tr·∫≠n nh·ªè (< 1000√ó1000)
- C·∫ßn exact decomposition
- Dense matrix

ALS Approximate:
- Ma tr·∫≠n l·ªõn (> 10K√ó10K)  ‚Üê Recommendation systems
- Sparse matrix (99% zeros)
- C·∫ßn regularization
- Mu·ªën t·ªëc ƒë·ªô
```

###### **4. V√≠ d·ª• minh h·ªça t·ª´ng b∆∞·ªõc**

**Input:**
```python
R = [[5, 3, 0],
     [4, 0, 5],
     [0, 4, 3]]
k = 2
```

**Iteration 1:**
```python
# Random init
U = [[0.1, 0.2],
     [0.3, 0.1],
     [0.2, 0.3]]

Vt = [[0.4, 0.2, 0.3],
      [0.1, 0.5, 0.2]]

# Compute error
R_predicted = U @ Œ£ @ Vt
error = ||R - R_predicted||¬≤ = 25.3
```

**Iteration 2:**
```python
# Update U (fix Vt)
U = [[-0.52, -0.18],
     [-0.41, -0.29],
     [-0.38,  0.58]]

# Update Vt (fix U)
Vt = [[-0.43, -0.35, -0.28],
       [ 0.12, -0.48, -0.68]]

# Update Œ£
Œ£ = [8.94, 4.81]

error = 3.7  # Gi·∫£m!
```

**Iteration 50:**
```python
# Converged!
U = [[-0.58, -0.15],
     [-0.45, -0.32],
     [-0.41,  0.61]]

Œ£ = [9.72, 5.22]

Vt = [[-0.46, -0.38, -0.30],
      [ 0.14, -0.52, -0.72]]

error = 0.001  # R·∫•t nh·ªè ‚Üí d·ª´ng
```

###### **5. T·∫°i sao U c√≥ gi√° tr·ªã √¢m?**

**U v√† Vt c√≥ th·ªÉ √¢m** v√¨ ch√∫ng ƒë·∫°i di·ªán cho **directions** (h∆∞·ªõng), kh√¥ng ph·∫£i magnitudes (ƒë·ªô l·ªõn):

```
User 1: [-0.58, -0.15]
         ‚Üì
    Gi√° tr·ªã √¢m ‚Üí User "ph·∫£n ƒë·ªëi" factor n√†y
    Gi√° tr·ªã d∆∞∆°ng ‚Üí User "·ªßng h·ªô" factor n√†y

V√≠ d·ª•:
- Factor 1 c√≥ th·ªÉ l√† "Casual Games"
- User 1: -0.58 ‚Üí Kh√¥ng th√≠ch casual ‚Üí Th√≠ch hardcore games
- User 3: +0.41 ‚Üí Th√≠ch casual games
```

**D·∫•u c·ªßa U v√† Vt ph·∫£i match:**
```
predicted_rating = U[user] @ Œ£ @ Vt[game]

N·∫øu:
- U[user][0] = -0.58 (√¢m)
- Vt[0][game] = -0.46 (√¢m)
‚Üí Contribution = -0.58 √ó 9.72 √ó -0.46 = +2.59 (d∆∞∆°ng!)

‚Üí User "kh√¥ng th√≠ch casual" √ó Game "kh√¥ng casual" = Rating cao!
```

###### **6. Code implementation th·ª±c t·∫ø**

```python
from scipy.sparse.linalg import svds
import numpy as np

def train_svd(ratings_matrix, k=100):
    """
    Train SVD model
    
    Args:
        ratings_matrix: (m users √ó n games) sparse matrix
        k: number of latent factors
    
    Returns:
        U, sigma, Vt
    """
    # Handle missing values (0s in sparse matrix)
    # SVD works best with mean-centered data
    user_ratings_mean = np.mean(ratings_matrix, axis=1)
    R_demeaned = ratings_matrix - user_ratings_mean.reshape(-1, 1)
    
    # Perform SVD
    U, sigma, Vt = svds(R_demeaned, k=k)
    
    # Sort by singular values (descending)
    idx = sigma.argsort()[::-1]
    U = U[:, idx]
    sigma = sigma[idx]
    Vt = Vt[idx, :]
    
    return U, sigma, Vt, user_ratings_mean

def predict_rating(user_id, game_id, U, sigma, Vt, user_means):
    """
    Predict rating for user-game pair
    """
    # Dot product through sigma
    prediction = np.dot(
        np.dot(U[user_id, :], np.diag(sigma)),
        Vt[:, game_id]
    )
    
    # Add back user mean
    prediction += user_means[user_id]
    
    # Clip to valid range [1, 5]
    prediction = np.clip(prediction, 1, 5)
    
    return prediction
```

**S·ª≠ d·ª•ng:**
```python
# Train
U, sigma, Vt, means = train_svd(ratings_matrix, k=100)

# Predict
predicted_rating = predict_rating(
    user_id=123,
    game_id=456,
    U=U,
    sigma=sigma,
    Vt=Vt,
    user_means=means
)

print(f"Predicted rating: {predicted_rating:.2f}")
# Output: Predicted rating: 4.28
```

---

##### **B∆∞·ªõc 3: D·ª± ƒëo√°n rating cho game m·ªõi**

Khi user ch∆∞a t∆∞∆°ng t√°c v·ªõi game, ta d·ª± ƒëo√°n rating b·∫±ng c√¥ng th·ª©c:

```python
predicted_rating[user_id][game_id] = U[user_id] @ Œ£ @ V·µÄ[game_id]
```

**Chi ti·∫øt ph√©p t√≠nh:**

```python
# 1. L·∫•y user vector (k factors)
user_vector = U[user_id]  # Shape: (k,)
# V√≠ d·ª•: [0.23, -0.15, 0.87, 0.42]

# 2. L·∫•y game vector (k factors)
game_vector = V·µÄ[:, game_id]  # Shape: (k,)
# V√≠ d·ª•: [0.45, 0.32, -0.18, 0.61]

# 3. T√≠nh t√≠ch v√¥ h∆∞·ªõng (dot product) qua Œ£
predicted_rating = sum(
    user_vector[i] * singular_values[i] * game_vector[i]
    for i in range(k)
)

# V·ªõi Œ£ = [3.5, 2.8, 2.1, 1.6]:
# = 0.23*3.5*0.45 + (-0.15)*2.8*0.32 + 0.87*2.1*(-0.18) + 0.42*1.6*0.61
# = 0.362 + (-0.134) + (-0.329) + 0.410
# = 0.309 (tr∆∞·ªõc khi rescale)
```

**Gi·∫£i th√≠ch:**
- N·∫øu user_vector v√† game_vector **c√πng h∆∞·ªõng** (dot product l·ªõn) ‚Üí user s·∫Ω th√≠ch game
- N·∫øu **ng∆∞·ª£c h∆∞·ªõng** (dot product nh·ªè) ‚Üí user kh√¥ng th√≠ch game

---

##### **B∆∞·ªõc 4: Chu·∫©n h√≥a v·ªÅ kho·∫£ng [0, 1]**

```python
# T√¨m min/max predicted ratings trong to√†n b·ªô dataset
min_rating = min(all_predicted_ratings)  # V√≠ d·ª•: 0.8
max_rating = max(all_predicted_ratings)  # V√≠ d·ª•: 4.9

# Normalize
svd_normalized = (predicted_rating - min_rating) / (max_rating - min_rating)

# V√≠ d·ª• v·ªõi predicted_rating = 4.2:
svd_normalized = (4.2 - 0.8) / (4.9 - 0.8) = 3.4 / 4.1 = 0.829
```

---

#### üìä V√≠ d·ª• ƒë·∫ßy ƒë·ªß:

```python
# === B∆∞·ªõc 1: X√¢y d·ª±ng ma tr·∫≠n ===
User 123:
- Wishlist: [Game A, Game B]          ‚Üí weight = [3.0, 3.0]
- Purchased: {Game C: 4, Game D: 5}   ‚Üí weight = [4.0, 5.0]
- Views: {Game E: 3, Game F: 7}       ‚Üí weight = [1.5, 3.5]

ratings_matrix[123] = [3.0, 3.0, 4.0, 5.0, 1.5, 3.5, 0, 0, ...]

# === B∆∞·ªõc 2: SVD Decomposition ===
U, Œ£, V·µÄ = SVD(ratings_matrix, k=100)  # 100 latent factors

# User 123 vector (100 dimensions):
U[123] = [0.23, -0.15, 0.87, 0.42, ..., 0.19]

# Game X vector (100 dimensions):
V·µÄ[:, game_x] = [0.45, 0.32, -0.18, 0.61, ..., -0.12]

# Singular values (100 values):
Œ£ = [3.5, 2.8, 2.1, 1.6, ..., 0.03]

# === B∆∞·ªõc 3: D·ª± ƒëo√°n rating ===
predicted_rating = U[123] @ Œ£ @ V·µÄ[:, game_x]
predicted_rating = 4.28  # Raw prediction

# === B∆∞·ªõc 4: Normalize ===
min_rating = 0.8
max_rating = 4.9
svd_normalized = (4.28 - 0.8) / (4.9 - 0.8)
svd_normalized = 0.849

# üéØ SVD Score cho Game X = 0.849
```

---

#### üîç T·∫°i sao SVD ho·∫°t ƒë·ªông t·ªët?

1. **T√¨m hidden patterns:**
   - Factor 1 c√≥ th·ªÉ ƒë·∫°i di·ªán cho "Games b·∫°o l·ª±c"
   - Factor 2 c√≥ th·ªÉ ƒë·∫°i di·ªán cho "Games ƒë·ªì h·ªça ƒë·∫πp"
   - Factor 3 c√≥ th·ªÉ ƒë·∫°i di·ªán cho "Games multiplayer"
   - ...

2. **X·ª≠ l√Ω sparsity (ma tr·∫≠n th∆∞a):**
   - H·∫ßu h·∫øt users ch·ªâ t∆∞∆°ng t√°c v·ªõi < 1% games
   - SVD "ƒëi·ªÅn v√†o ch·ªó tr·ªëng" d·ª±a tr√™n patterns t·ª´ users t∆∞∆°ng t·ª±

3. **Generalization:**
   - Kh√¥ng c·∫ßn game v√† user gi·ªëng h·ªát nhau
   - Ch·ªâ c·∫ßn "latent preferences" t∆∞∆°ng t·ª±

---

#### ‚ö†Ô∏è Gi·ªõi h·∫°n c·ªßa SVD:

1. **Cold Start Problem:**
   - User m·ªõi kh√¥ng c√≥ l·ªãch s·ª≠ ‚Üí U[new_user] kh√¥ng ch√≠nh x√°c
   - Game m·ªõi kh√¥ng ai t∆∞∆°ng t√°c ‚Üí V·µÄ[:, new_game] kh√¥ng ch√≠nh x√°c
   - **Gi·∫£i ph√°p:** K·∫øt h·ª£p v·ªõi Content Score v√† Demographic Score

2. **Overfitting:**
   - N·∫øu k qu√° l·ªõn ‚Üí model "ghi nh·ªõ" noise
   - **Gi·∫£i ph√°p:** S·ª≠ d·ª•ng SVD++ ho·∫∑c cross-validation ƒë·ªÉ ch·ªçn k t·ªëi ∆∞u

3. **Kh√¥ng gi·∫£i th√≠ch ƒë∆∞·ª£c:**
   - Factors l√† tr·ª´u t∆∞·ª£ng, kh√¥ng c√≥ √Ω nghƒ©a r√µ r√†ng
   - **Gi·∫£i ph√°p:** K·∫øt h·ª£p v·ªõi content-based ƒë·ªÉ gi·∫£i th√≠ch g·ª£i √Ω

---

### 2Ô∏è‚É£ **Content Score** (Content-based Filtering)
> ƒêo ƒë·ªô t∆∞∆°ng ƒë·ªìng gi·ªØa game v√† games m√† user ƒë√£ th√≠ch

#### üìê C√°ch t√≠nh:
- S·ª≠ d·ª•ng **TF-IDF + Cosine Similarity**
- ƒê·∫∑c tr∆∞ng game:
  - `genre` (th·ªÉ lo·∫°i): Action, RPG, Strategy...
  - `platform`: Windows, Mac, Linux...
  - `publisher`: EA, Ubisoft, Valve...
  - `language`: English, Vietnamese...
  - `mode`: Single Player, Multiplayer, Co-op...
  - `age_rating`: Everyone, Teen, Mature...

#### üî¢ C√¥ng th·ª©c:
```python
# 1. T·∫°o feature vector cho m·ªói game
game_features = [genre, platform, publisher, language, mode, age_rating]

# 2. TF-IDF vectorization
tfidf_matrix = TF_IDF(all_games_features)

# 3. Cosine similarity matrix
similarity_matrix = cosine_similarity(tfidf_matrix, tfidf_matrix)

# 4. Content score cho game m·ªõi = trung b√¨nh similarity v·ªõi games ƒë√£ t∆∞∆°ng t√°c
content_score = mean([
    similarity_matrix[new_game_id][interacted_game_id] 
    for interacted_game_id in user_interacted_games
])

# 5. ƒêi·ªÅu ch·ªânh ƒë·ªÉ ƒë·∫£m b·∫£o d∆∞∆°ng (n·∫øu c√≥ gi√° tr·ªã √¢m)
if min_content_score < 0:
    content_score += abs(min_content_score)
```

#### üìä V√≠ d·ª•:
```
User ƒë√£ th√≠ch:
- Game A: Action, Windows, EA ‚Üí similarity = 0.85 v·ªõi Game X
- Game B: RPG, Windows, EA ‚Üí similarity = 0.62 v·ªõi Game X
- Game C: Action, Mac, Ubisoft ‚Üí similarity = 0.73 v·ªõi Game X

Content Score c·ªßa Game X = (0.85 + 0.62 + 0.73) / 3 = 0.733
```

---

### 3Ô∏è‚É£ **Demographic Score**
> G·ª£i √Ω games ph·ªï bi·∫øn v·ªõi nh√≥m ng∆∞·ªùi d√πng t∆∞∆°ng t·ª± (age, gender)

#### üìê C√°ch t√≠nh:
- T√¨m users c√≥ demographic t∆∞∆°ng t·ª±:
  - `age`: ¬±5 tu·ªïi
  - `gender`: c√πng gi·ªõi t√≠nh ho·∫∑c `Other`
  
- T√≠nh popularity score c·ªßa game trong nh√≥m:

#### üî¢ C√¥ng th·ª©c:
```python
# 1. T√¨m similar users
similar_users = [
    user for user in all_users
    if abs(user.age - current_user.age) <= 5
    and (user.gender == current_user.gender or user.gender == 'Other')
]

# 2. T√≠nh popularity trong nh√≥m
popularity_score = 0
for user in similar_users:
    if game_id in user.purchased_games:
        popularity_score += user.purchased_games[game_id]  # rating 1-5
    elif game_id in user.favorite_games:
        popularity_score += 3  # default rating
    elif game_id in user.view_history:
        popularity_score += user.view_history[game_id] * 0.5

# 3. Normalize
demographic_score = popularity_score / len(similar_users)

# 4. Normalize to 0-1
demographic_normalized = demographic_score / 5.0
```

#### üìä V√≠ d·ª•:
```
User: age=25, gender=Male
Similar users: 15 users (age 20-30, Male)

Game X popularity:
- 5 users purchased (avg rating: 4.2)
- 3 users wishlisted
- 7 users viewed (avg: 2 views)

Demographic Score = (5√ó4.2 + 3√ó3 + 7√ó2√ó0.5) / 15 = 3.13
Normalized = 3.13 / 5.0 = 0.626
```

---

### 4Ô∏è‚É£ **Keyword Score** (Semantic Search)
> ƒêo ƒë·ªô li√™n quan c·ªßa game v·ªõi t·ª´ kh√≥a t√¨m ki·∫øm

#### üìê C√°ch t√≠nh:
Keyword score ƒë∆∞·ª£c t√≠nh d·ª±a tr√™n 8 tr∆∞·ªùng (whole word matching):

| Tr∆∞·ªùng | ƒêi·ªÉm n·∫øu match | V√≠ d·ª• |
|--------|----------------|-------|
| `name` | 3.0 | "Call of Duty" match "call" |
| `genre` | 2.5 | ["Action", "FPS"] match "action" |
| `description` | 2.0 | M√¥ t·∫£ c√≥ "multiplayer shooter" |
| `publisher` | 1.5 | "Activision" match "activision" |
| `platform` | 1.5 | ["Windows", "Xbox"] match "windows" |
| `language` | 1.5 | ["English", "Vietnamese"] match "vietnamese" |
| `mode` | 1.0 | ["Single", "Multi"] match "single" |
| `age_rating` | 1.0 | "Mature" match "mature" |

#### üî¢ C√¥ng th·ª©c:
```python
def get_keyword_score(game, keyword):
    if not keyword:
        return 0.0
    
    score = 0.0
    keywords_to_search = keyword.lower().split()
    
    searchable_fields = {
        'name': 3.0,           # T√™n game quan tr·ªçng nh·∫•t
        'genre': 2.5,          # Genre quan tr·ªçng
        'description': 2.0,    # M√¥ t·∫£ quan tr·ªçng th·ª© 2
        'publisher': 1.5,      # Publisher
        'platform': 1.5,       # Platform
        'language': 1.5,       # Language
        'mode': 1.0,           # Mode
        'age_rating': 1.0,     # Age rating
    }
    
    # T√¨m trong text fields (whole word matching)
    for field, weight in searchable_fields.items():
        field_value = game.get(field, '')
        if isinstance(field_value, list):
            field_value = ' '.join(field_value)
        field_value = str(field_value).lower()
        
        # T√°ch th√†nh t·ª´ng t·ª´
        field_words = field_value.split()
        for kw in keywords_to_search:
            if len(kw) >= 2 and kw in field_words:  # Whole word match
                score += weight
                break  # Ch·ªâ t√≠nh 1 l·∫ßn cho m·ªói field
    
    # Normalize to 0-1 (max possible score = 13.5)
    return score / 13.5
```

#### üìä V√≠ d·ª•:
```
Keyword: "call of duty"
Keywords to search: ["call", "of", "duty"]

Game: Call of Duty: Modern Warfare
- Name: "Call of Duty Modern Warfare" ‚Üí words: ["call", "of", "duty", ...] ‚Üí match "call" ‚Üí +3.0
- Genre: ["Action", "FPS"] ‚Üí kh√¥ng match ‚Üí +0
- Description: "...popular shooter..." ‚Üí kh√¥ng match ‚Üí +0
- Publisher: "Activision" ‚Üí kh√¥ng match ‚Üí +0

Total: 3.0
Normalized: 3.0 / 13.5 = 0.222

Game: Battlefield 2042
- Name: "Battlefield 2042" ‚Üí kh√¥ng match ‚Üí +0
- Genre: ["Action", "FPS"] ‚Üí match "action" ‚Üí +2.5
- Description: "multiplayer shooter" ‚Üí kh√¥ng match ‚Üí +0

Total: 2.5
Normalized: 2.5 / 13.5 = 0.185
```

---

## ‚öñÔ∏è Tr·ªçng s·ªë (Weights) - ƒêi·ªÅu ch·ªânh ƒë·ªông

H·ªá th·ªëng s·ª≠ d·ª•ng **3 b·ªô tr·ªçng s·ªë** kh√°c nhau t√πy theo t√¨nh hu·ªëng:

### üìä B·∫£ng tr·ªçng s·ªë

| T√¨nh hu·ªëng | SVD (W‚ÇÅ) | Content (W‚ÇÇ) | Demographic (W‚ÇÉ) | Keyword (W‚ÇÑ) | T·ªïng |
|------------|----------|--------------|------------------|--------------|------|
| **Regular (No Keyword)** | 0.50 | 0.30 | 0.20 | 0.00 | 1.00 |
| **With Keyword** | 0.15 | 0.15 | 0.10 | 0.60 | 1.00 |
| **Cold Start (No Keyword)** | 0.50 | 0.00 | 0.50 | 0.00 | 1.00 |
| **Cold Start (With Keyword)** | 0.20 | 0.00 | 0.20 | 0.60 | 1.00 |

### üéØ Gi·∫£i th√≠ch t·ª´ng tr∆∞·ªùng h·ª£p:

#### 1. **Regular User - No Keyword** (W = 0.50, 0.30, 0.20, 0.00)
```python
WEIGHTS_NO_KEYWORD = {
    'svd': 0.50,         # ‚Üë ∆Øu ti√™n collaborative filtering
    'content': 0.30,     # ‚Üë Content similarity quan tr·ªçng
    'demographic': 0.20, # ‚Üì Demographic √≠t quan tr·ªçng h∆°n
    'keyword': 0.00      # Kh√¥ng c√≥ keyword
}
```

**L√Ω do:**
- User c√≥ l·ªãch s·ª≠ t∆∞∆°ng t√°c ‚Üí SVD ho·∫°t ƒë·ªông t·ªët
- Content similarity gi√∫p t√¨m games t∆∞∆°ng t·ª± nh·ªØng g√¨ user th√≠ch
- Demographic c√≥ t√°c ƒë·ªông nh·ªè

#### 2. **Regular User - With Keyword** (W = 0.15, 0.15, 0.10, 0.60)
```python
WEIGHTS_WITH_KEYWORD = {
    'svd': 0.15,         # ‚Üì Gi·∫£m SVD v√¨ user ƒëang t√¨m c√°i c·ª• th·ªÉ
    'content': 0.15,     # ‚Üì Gi·∫£m content
    'demographic': 0.10, # ‚Üì Gi·∫£m demographic
    'keyword': 0.60      # ‚Üë‚Üë ∆Øu ti√™n keyword search
}
```

**L√Ω do:**
- User ƒëang t√¨m game c·ª• th·ªÉ ‚Üí keyword l√† ∆∞u ti√™n h√†ng ƒë·∫ßu
- C√°c th√†nh ph·∫ßn kh√°c c√≥ vai tr√≤ ph·ª• ƒë·ªÉ re-rank k·∫øt qu·∫£

#### 3. **Cold Start User - No Keyword** (W = 0.50, 0.00, 0.50, 0.00)
```python
WEIGHTS_COLD_START_NO_KEYWORD = {
    'svd': 0.50,         # ‚Üë SVD v·∫´n ho·∫°t ƒë·ªông (d√πng patterns t·ª´ all users)
    'content': 0.00,     # ‚ö†Ô∏è Kh√¥ng c√≥ l·ªãch s·ª≠ ‚Üí kh√¥ng t√≠nh content
    'demographic': 0.50, # ‚Üë‚Üë D·ª±a v√†o demographic similarity
    'keyword': 0.00      # Kh√¥ng c√≥ keyword
}
```

**L√Ω do:**
- User m·ªõi ch∆∞a c√≥ l·ªãch s·ª≠ ‚Üí kh√¥ng t√≠nh ƒë∆∞·ª£c content similarity
- Demographic tr·ªü th√†nh y·∫øu t·ªë ch√≠nh (g·ª£i √Ω games ph·ªï bi·∫øn v·ªõi nh√≥m tu·ªïi/gi·ªõi t√≠nh)

#### 4. **Cold Start User - With Keyword** (W = 0.20, 0.00, 0.20, 0.60)
```python
WEIGHTS_COLD_START_WITH_KEYWORD = {
    'svd': 0.20,         # ‚Üì SVD c√≥ vai tr√≤ nh·ªè
    'content': 0.00,     # ‚ö†Ô∏è Kh√¥ng t√≠nh content
    'demographic': 0.20, # ‚Üì Demographic c√≥ vai tr√≤ ph·ª•
    'keyword': 0.60      # ‚Üë‚Üë ∆Øu ti√™n keyword
}
```

**L√Ω do:**
- User m·ªõi + c√≥ keyword ‚Üí keyword l√† ch√≠nh
- SVD v√† demographic ch·ªâ ƒë·ªÉ re-rank

---

## ü§ñ Dynamic Weight Adjustment (ƒêi·ªÅu ch·ªânh tr·ªçng s·ªë th√¥ng minh)

H·ªá th·ªëng t·ª± ƒë·ªông ƒëi·ªÅu ch·ªânh tr·ªçng s·ªë d·ª±a tr√™n **h√†nh vi user**:

### üìä Case 1: User th∆∞·ªùng kh√°m ph√° ngo√†i top 10 g·ª£i √Ω

**ƒêi·ªÅu ki·ªán:**
- `ratio_outside_top10 > 0.5` (50% games user ch·ªçn n·∫±m ngo√†i top 10 g·ª£i √Ω)

**ƒêi·ªÅu ch·ªânh:**
```python
# C√¥ng th·ª©c gi·∫£m keyword weight
keyword_reduction_percent = (ratio_outside_top10 - 0.5) * 50

# V√≠ d·ª•: ratio = 0.70 ‚Üí gi·∫£m 10%
# (0.70 - 0.5) * 50 = 10%

new_keyword_weight = 0.60 - (0.60 * keyword_reduction_percent / 100)
# = 0.60 - 0.06 = 0.54

# Ph√¢n b·ªï l∆∞·ª£ng gi·∫£m:
content_increase = keyword_reduction * 0.6  # 60% cho content
demographic_increase = keyword_reduction * 0.4  # 40% cho demographic

new_content_weight = 0.15 + content_increase
new_demographic_weight = 0.10 + demographic_increase
```

**B·∫£ng ƒëi·ªÅu ch·ªânh:**

| Ratio Outside Top 10 | Keyword Reduction | New Weights (SVD, Content, Demo, Keyword) |
|----------------------|-------------------|-------------------------------------------|
| 50% | 0% | 0.15, 0.15, 0.10, 0.60 (kh√¥ng ƒë·ªïi) |
| 60% | 5% | 0.15, 0.168, 0.112, 0.57 |
| 70% | 10% | 0.15, 0.186, 0.124, 0.54 |
| 80% | 15% | 0.15, 0.204, 0.136, 0.51 |
| 90% | 20% | 0.15, 0.222, 0.148, 0.48 |
| 100% | 25% | 0.15, 0.240, 0.160, 0.45 |

**L√Ω do:**
- User th∆∞·ªùng kh√°m ph√° ‚Üí gi·∫£m ·∫£nh h∆∞·ªüng c·ªßa keyword
- TƒÉng content v√† demographic ƒë·ªÉ ƒëa d·∫°ng h√≥a g·ª£i √Ω

---

### üìä Case 2: User c√≥ preferences m·∫°nh (publisher/genre)

**ƒêi·ªÅu ki·ªán:**
- `preference_strength >= 0.4` (user c√≥ preferences r√µ r√†ng v·ªÅ publisher ho·∫∑c genre)

**ƒêi·ªÅu ch·ªânh:**
```python
adjusted_weights = {
    'svd': 0.10,          # ‚Üì Gi·∫£m SVD
    'content': 0.25,      # ‚Üë TƒÉng content (t·ª´ 0.15 ‚Üí 0.25)
    'demographic': 0.05,  # ‚Üì Gi·∫£m demographic
    'keyword': 0.60       # Gi·ªØ keyword
}
```

**L√Ω do:**
- User c√≥ preferences m·∫°nh ‚Üí content similarity ho·∫°t ƒë·ªông r·∫•t t·ªët
- TƒÉng content weight ƒë·ªÉ ∆∞u ti√™n games c√≥ genre/publisher gi·ªëng v·ªõi nh·ªØng g√¨ user th√≠ch

---

## üßÆ V√≠ d·ª• t√≠nh Base Score ƒë·∫ßy ƒë·ªß

### T√¨nh hu·ªëng: User 123 t√¨m ki·∫øm "action game"

**Th√¥ng tin user:**
```
User 123:
- Age: 25, Gender: Male
- Wishlist: [Game A (Action), Game B (RPG)]
- Purchased: {Game C (Action): rating=4, Game D (FPS): rating=5}
- Views: {Game E (Strategy): 3 views, Game F (Action): 7 views}
- Behavior: 40% games ngo√†i top 10 (kh√¥ng trigger adjustment)
- Preference strength: 0.6 (strong genre preference for Action)
```

**Game X c·∫ßn t√≠nh score:**
```
Game X: "Call of Duty: Modern Warfare"
- Genre: ["Action", "FPS"]
- Platform: ["Windows", "Xbox"]
- Publisher: "Activision"
- Price: 1,500,000 VND
- Rating: 4.5/5
```

---

### B∆∞·ªõc 1: T√≠nh t·ª´ng component score

#### 1.1. SVD Score
```python
# User interactions:
# - Game A (wishlist): 3.0
# - Game B (wishlist): 3.0
# - Game C (purchased): 4.0
# - Game D (purchased): 5.0
# - Game E (3 views): 1.5
# - Game F (7 views): 3.5

# SVD prediction
predicted_rating = 4.3  # t·ª´ ma tr·∫≠n decomposition

# Normalize
svd_min = 1.0
svd_max = 5.0
svd_normalized = (4.3 - 1.0) / (5.0 - 1.0) = 0.825
```

**SVD Score = 0.825**

---

#### 1.2. Content Score
```python
# Game X features:
game_x_features = "Action FPS Windows Xbox Activision"

# User ƒë√£ t∆∞∆°ng t√°c v·ªõi:
# - Game A (Action, Windows, EA)
# - Game B (RPG, Mac, Ubisoft)
# - Game C (Action, Windows, EA)
# - Game D (FPS, Windows, Valve)
# - Game F (Action, Xbox, Activision) ‚Üê 7 views (high weight)

# Cosine similarity:
similarity_with_A = 0.78
similarity_with_B = 0.42
similarity_with_C = 0.81
similarity_with_D = 0.85
similarity_with_E = 0.35
similarity_with_F = 0.92  # Very similar!

# Weighted average (d·ª±a tr√™n interaction strength)
content_score = (
    3.0 * 0.78 +  # Game A (wishlist)
    3.0 * 0.42 +  # Game B (wishlist)
    4.0 * 0.81 +  # Game C (purchased, rating=4)
    5.0 * 0.85 +  # Game D (purchased, rating=5)
    1.5 * 0.35 +  # Game E (3 views)
    3.5 * 0.92    # Game F (7 views)
) / (3.0 + 3.0 + 4.0 + 5.0 + 1.5 + 3.5)

content_score = 14.17 / 20.0 = 0.709
```

**Content Score = 0.709**

---

#### 1.3. Demographic Score
```python
# Similar users (age 20-30, Male): 18 users

# Game X popularity trong nh√≥m:
# - 6 users purchased (avg rating: 4.3)
# - 4 users wishlisted
# - 8 users viewed (avg: 2.5 views)

popularity_score = (
    6 * 4.3 +        # Purchased
    4 * 3.0 +        # Wishlisted (default rating = 3)
    8 * 2.5 * 0.5    # Viewed
) / 18

popularity_score = (25.8 + 12.0 + 10.0) / 18 = 2.656

# Normalize to 0-1
demographic_normalized = 2.656 / 5.0 = 0.531
```

**Demographic Score = 0.531**

---

#### 1.4. Keyword Score
```python
keyword = "action game"
keywords_to_search = ["action", "game"]

# Game X: "Call of Duty: Modern Warfare"
# - Name: "Call of Duty Modern Warfare" ‚Üí kh√¥ng match ‚Üí 0
# - Genre: ["Action", "FPS"] ‚Üí match "action" ‚Üí +2.5
# - Description: "...multiplayer shooter game..." ‚Üí match "game" ‚Üí +2.0
# - Publisher: "Activision" ‚Üí 0
# - Platform: ["Windows", "Xbox"] ‚Üí 0
# - Language: ["English"] ‚Üí 0
# - Mode: ["Multiplayer"] ‚Üí 0
# - Age rating: "Mature" ‚Üí 0

total_score = 2.5 + 2.0 = 4.5

# Normalize
keyword_score = 4.5 / 13.5 = 0.333
```

**Keyword Score = 0.333**

---

### B∆∞·ªõc 2: Ch·ªçn tr·ªçng s·ªë

**User 123 c√≥:**
- ‚úÖ L·ªãch s·ª≠ t∆∞∆°ng t√°c (kh√¥ng ph·∫£i cold start)
- ‚úÖ C√≥ keyword t√¨m ki·∫øm ("action game")
- ‚ö†Ô∏è Preference strength = 0.6 (>0.4) ‚Üí Trigger Case 2 adjustment!

**Adjusted Weights:**
```python
weights = {
    'svd': 0.10,         # ‚Üì Gi·∫£m SVD
    'content': 0.25,     # ‚Üë TƒÉng content (v√¨ preference m·∫°nh)
    'demographic': 0.05, # ‚Üì Gi·∫£m demographic
    'keyword': 0.60      # Gi·ªØ keyword
}
```

---

### B∆∞·ªõc 3: T√≠nh Base Score

```python
base_score = (
    svd_weight       * svd_score +
    content_weight   * content_score +
    demographic_weight * demographic_score +
    keyword_weight   * keyword_score
)

base_score = (
    0.10 * 0.825 +
    0.25 * 0.709 +
    0.05 * 0.531 +
    0.60 * 0.333
)

base_score = 0.0825 + 0.1773 + 0.0266 + 0.1998

base_score = 0.4862
```

### üìä K·∫øt qu·∫£ Base Score

```
‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó
‚ïë  GAME: Call of Duty: Modern Warfare                        ‚ïë
‚ïë  USER: 123 (Age: 25, Male)                                 ‚ïë
‚ïë  KEYWORD: "action game"                                    ‚ïë
‚ï†‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï£
‚ïë  Component Scores:                                         ‚ïë
‚ïë  ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïë
‚ïë  ‚Ä¢ SVD Score:         0.825  (√ó 0.10) = 0.0825            ‚ïë
‚ïë  ‚Ä¢ Content Score:     0.709  (√ó 0.25) = 0.1773            ‚ïë
‚ïë  ‚Ä¢ Demographic Score: 0.531  (√ó 0.05) = 0.0266            ‚ïë
‚ïë  ‚Ä¢ Keyword Score:     0.333  (√ó 0.60) = 0.1998            ‚ïë
‚ïë  ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïë
‚ïë  üéØ BASE SCORE:       0.4862                               ‚ïë
‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù
```

---

## üéØ L∆∞u √Ω quan tr·ªçng

### ‚úÖ Base Score vs Boosted Score

```
Base Score: 0.4382  ‚Üê ƒêi·ªÉm ban ƒë·∫ßu (tr∆∞·ªõc boost)
                     
                     ‚Üì √Åp d·ª•ng Adaptive Boost (n·∫øu enable_adaptive=true)
                     
Boosted Score: 0.526 ‚Üê ƒêi·ªÉm cu·ªëi c√πng (sau boost)
```

### üìä Khi n√†o Base Score cao?

Base Score cao khi game c√≥:
- ‚úÖ **SVD Score cao**: User t∆∞∆°ng t·ª± ƒë√£ th√≠ch game n√†y
- ‚úÖ **Content Score cao**: Game t∆∞∆°ng t·ª± nh·ªØng g√¨ user ƒë√£ th√≠ch
- ‚úÖ **Demographic Score cao**: Ph·ªï bi·∫øn trong nh√≥m tu·ªïi/gi·ªõi t√≠nh
- ‚úÖ **Keyword Score cao**: Match t·ªët v·ªõi t·ª´ kh√≥a t√¨m ki·∫øm

### ‚ö†Ô∏è C√°c tr∆∞·ªùng h·ª£p ƒë·∫∑c bi·ªát

#### Cold Start User
- Content Score = 0 (kh√¥ng c√≥ l·ªãch s·ª≠)
- Ch·ªâ d·ª±a v√†o SVD + Demographic + Keyword
- Base Score th∆∞·ªùng th·∫•p h∆°n regular users

#### No Keyword Search
- Keyword Score = 0
- Tr·ªçng s·ªë ph√¢n b·ªï l·∫°i cho SVD + Content + Demographic
- Base Score ph·ª• thu·ªôc nhi·ªÅu v√†o collaborative v√† content filtering

---

## üìà So s√°nh Base Score gi·ªØa c√°c games

### V√≠ d·ª•: Top 5 games cho User 123 (keyword: "action game")

| Rank | Game Name | SVD | Content | Demo | Keyword | **Base Score** |
|------|-----------|-----|---------|------|---------|----------------|
| 1 | Call of Duty: MW | 0.825 | 0.757 | 0.531 | 0.233 | **0.4382** |
| 2 | Battlefield 2042 | 0.712 | 0.823 | 0.612 | 0.200 | **0.4316** |
| 3 | Apex Legends | 0.645 | 0.689 | 0.734 | 0.167 | **0.3845** |
| 4 | Valorant | 0.598 | 0.712 | 0.689 | 0.133 | **0.3623** |
| 5 | Overwatch 2 | 0.534 | 0.645 | 0.723 | 0.100 | **0.3356** |

**Ph√¢n t√≠ch:**
- Call of Duty d·∫´n ƒë·∫ßu v√¨ c√≥ **SVD cao** (0.825) v√† **Content match t·ªët** (0.757)
- Battlefield x·∫øp th·ª© 2 do **Content Score r·∫•t cao** (0.823) nh∆∞ng SVD th·∫•p h∆°n
- Apex, Valorant, Overwatch c√≥ keyword score th·∫•p h∆°n ‚Üí x·∫øp sau

---

## üîó T√†i li·ªáu li√™n quan

- üìÑ [HUONG_DAN_ADAPTIVE_BOOST.md](./HUONG_DAN_ADAPTIVE_BOOST.md) - Gi·∫£i th√≠ch c√°ch boost factor ƒë∆∞·ª£c √°p d·ª•ng sau base score
- üìÑ [baocao.md](./baocao.md) - B√°o c√°o t·ªïng quan v·ªÅ h·ªá th·ªëng g·ª£i √Ω

---

## ‚ùì FAQ

### Q1: T·∫°i sao Content Score c√≥ th·ªÉ √¢m?
**A:** Content Score d·ª±a tr√™n cosine similarity, c√≥ th·ªÉ √¢m n·∫øu hai vectors ng∆∞·ª£c h∆∞·ªõng. H·ªá th·ªëng t·ª± ƒë·ªông ƒëi·ªÅu ch·ªânh b·∫±ng c√°ch c·ªông th√™m `abs(min_content_score)` ƒë·ªÉ ƒë·∫£m b·∫£o t·∫•t c·∫£ scores d∆∞∆°ng.

### Q2: Base Score c√≥ gi√° tr·ªã t·ª´ 0-1?
**A:** ƒê√∫ng, base score ƒë∆∞·ª£c chu·∫©n h√≥a v·ªÅ kho·∫£ng [0, 1] nh·ªù:
- SVD normalized v·ªÅ 0-1
- Content score v·ªÅ 0-1 (sau adjustment)
- Demographic normalized v·ªÅ 0-1 (chia cho 5)
- Keyword score v·ªÅ 0-1 (chia cho 15)

### Q3: T·∫°i sao c√πng 1 user nh∆∞ng base score c·ªßa game thay ƒë·ªïi khi c√≥/kh√¥ng keyword?
**A:** V√¨ tr·ªçng s·ªë thay ƒë·ªïi:
- **No keyword**: SVD=0.50, Content=0.30, Demo=0.20
- **With keyword**: SVD=0.15, Content=0.15, Demo=0.10, Keyword=0.60

Keyword score kh√°c 0 ‚Üí c√¥ng th·ª©c t√≠nh base score kh√°c ‚Üí k·∫øt qu·∫£ kh√°c.

### Q4: Base Score c√≥ th·ªÉ > 1 kh√¥ng?
**A:** L√Ω thuy·∫øt kh√¥ng (v√¨ c√°c component ƒë√£ normalized 0-1 v√† weights t·ªïng = 1.0). Nh∆∞ng trong th·ª±c t·∫ø hi·∫øm khi ƒë·∫°t 1.0 v√¨ kh√¥ng c√≥ game n√†o perfect match t·∫•t c·∫£ 4 ti√™u ch√≠.

### Q5: Adaptive Boost ·∫£nh h∆∞·ªüng ƒë·∫øn Base Score?
**A:** **KH√îNG**. Base Score t√≠nh tr∆∞·ªõc, sau ƒë√≥ m·ªõi √°p d·ª•ng boost factor:
```
Final Score = Base Score √ó Boost Factor
```

---

**üìÖ C·∫≠p nh·∫≠t l·∫ßn cu·ªëi: 02/11/2025**
**üë®‚Äçüíª T√°c gi·∫£: AI Assistant**

