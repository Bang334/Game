#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
GAME RECOMMENDATION WEB APP
Flask web application v·ªõi th√¥ng minh d·ª±a tr√™n t∆∞∆°ng t√°c ng∆∞·ªùi d√πng
"""

from flask import Flask, render_template, request, jsonify, session
import json
import os
import numpy as np
from datetime import datetime
import sqlite3
from game_recommendation_system import GameRecommendationSystem

app = Flask(__name__)
app.secret_key = 'game_recommendation_secret_key_2024'

# Kh·ªüi t·∫°o recommendation system
recommender = None
user_interactions = {}  # L∆∞u tr·ªØ t∆∞∆°ng t√°c ng∆∞·ªùi d√πng
learning_data = {}      # D·ªØ li·ªáu h·ªçc t·ª´ t∆∞∆°ng t√°c

def init_recommender():
    """Kh·ªüi t·∫°o recommendation system"""
    global recommender
    if recommender is None:
        print("üöÄ Kh·ªüi t·∫°o Game Recommendation System...")
        recommender = GameRecommendationSystem()
        recommender.load_data()
        recommender.preprocess_data()
        recommender.train_svd_model()
        recommender.build_content_similarity()
        print("‚úÖ H·ªá th·ªëng ƒë√£ s·∫µn s√†ng!")
    return recommender

def init_database():
    """Kh·ªüi t·∫°o database ƒë·ªÉ l∆∞u tr·ªØ t∆∞∆°ng t√°c"""
    conn = sqlite3.connect('user_interactions.db')
    cursor = conn.cursor()
    
    # B·∫£ng l∆∞u tr·ªØ t∆∞∆°ng t√°c ng∆∞·ªùi d√πng
    cursor.execute('''
        CREATE TABLE IF NOT EXISTS user_interactions (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            user_id INTEGER,
            game_id INTEGER,
            interaction_type TEXT,
            rating REAL,
            timestamp DATETIME DEFAULT CURRENT_TIMESTAMP
        )
    ''')
    
    # B·∫£ng l∆∞u tr·ªØ feedback
    cursor.execute('''
        CREATE TABLE IF NOT EXISTS user_feedback (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            user_id INTEGER,
            game_id INTEGER,
            feedback_type TEXT,
            score REAL,
            comment TEXT,
            timestamp DATETIME DEFAULT CURRENT_TIMESTAMP
        )
    ''')
    
    # B·∫£ng l∆∞u tr·ªØ learning data
    cursor.execute('''
        CREATE TABLE IF NOT EXISTS learning_data (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            user_id INTEGER,
            feature_name TEXT,
            feature_value REAL,
            weight REAL,
            timestamp DATETIME DEFAULT CURRENT_TIMESTAMP
        )
    ''')
    
    conn.commit()
    conn.close()
    print("‚úÖ Database ƒë√£ ƒë∆∞·ª£c kh·ªüi t·∫°o!")

def get_user_interactions(user_id):
    """L·∫•y t∆∞∆°ng t√°c c·ªßa user"""
    conn = sqlite3.connect('user_interactions.db')
    cursor = conn.cursor()
    
    cursor.execute('''
        SELECT game_id, interaction_type, rating, timestamp 
        FROM user_interactions 
        WHERE user_id = ? 
        ORDER BY timestamp DESC
    ''', (user_id,))
    
    interactions = cursor.fetchall()
    conn.close()
    
    return interactions

def save_user_interaction(user_id, game_id, interaction_type, rating=None):
    """L∆∞u t∆∞∆°ng t√°c ng∆∞·ªùi d√πng"""
    conn = sqlite3.connect('user_interactions.db')
    cursor = conn.cursor()
    
    cursor.execute('''
        INSERT INTO user_interactions (user_id, game_id, interaction_type, rating)
        VALUES (?, ?, ?, ?)
    ''', (user_id, game_id, interaction_type, rating))
    
    conn.commit()
    conn.close()
    
    # C·∫≠p nh·∫≠t learning data
    update_learning_data(user_id, game_id, interaction_type, rating)

def update_learning_data(user_id, game_id, interaction_type, rating):
    """C·∫≠p nh·∫≠t d·ªØ li·ªáu h·ªçc t·ª´ t∆∞∆°ng t√°c"""
    global learning_data
    
    if user_id not in learning_data:
        learning_data[user_id] = {
            'preferences': {},
            'behavior_patterns': {},
            'interaction_history': []
        }
    
    # L∆∞u l·ªãch s·ª≠ t∆∞∆°ng t√°c
    learning_data[user_id]['interaction_history'].append({
        'game_id': game_id,
        'type': interaction_type,
        'rating': rating,
        'timestamp': datetime.now()
    })
    
    # C·∫≠p nh·∫≠t preferences d·ª±a tr√™n t∆∞∆°ng t√°c
    if interaction_type == 'view':
        if 'viewed_games' not in learning_data[user_id]['preferences']:
            learning_data[user_id]['preferences']['viewed_games'] = []
        learning_data[user_id]['preferences']['viewed_games'].append(game_id)
    
    elif interaction_type == 'like':
        if 'liked_games' not in learning_data[user_id]['preferences']:
            learning_data[user_id]['preferences']['liked_games'] = []
        learning_data[user_id]['preferences']['liked_games'].append(game_id)
    
    elif interaction_type == 'purchase':
        if 'purchased_games' not in learning_data[user_id]['preferences']:
            learning_data[user_id]['preferences']['purchased_games'] = []
        learning_data[user_id]['preferences']['purchased_games'].append(game_id)
    
    # Ph√¢n t√≠ch behavior patterns
    analyze_user_behavior(user_id)
    
    # Ki·ªÉm tra c√≥ c·∫ßn retrain SVD model kh√¥ng
    check_and_retrain_svd(user_id)

def analyze_user_behavior(user_id):
    """Ph√¢n t√≠ch h√†nh vi ng∆∞·ªùi d√πng ƒë·ªÉ c·∫£i thi·ªán recommendations"""
    if user_id not in learning_data:
        return
    
    user_data = learning_data[user_id]
    interactions = user_data['interaction_history']
    
    if len(interactions) < 2:  # C·∫ßn √≠t nh·∫•t 2 t∆∞∆°ng t√°c ƒë·ªÉ ph√¢n t√≠ch
        return
    
    # Ph√¢n t√≠ch th·ªùi gian t∆∞∆°ng t√°c
    recent_interactions = [i for i in interactions if 
                         (datetime.now() - i['timestamp']).days <= 7]
    
    if len(recent_interactions) > 0:
        user_data['behavior_patterns']['active_recently'] = True
        user_data['behavior_patterns']['recent_activity_score'] = len(recent_interactions) / 7.0
    else:
        user_data['behavior_patterns']['active_recently'] = False
    
    # Ph√¢n t√≠ch lo·∫°i games ∆∞a th√≠ch
    game_types = {}
    release_dates = []
    price_ranges = []
    platforms = {}
    publishers = {}
    
    for interaction in interactions:
        # L·∫•y th√¥ng tin game t·ª´ recommender
        game_info = next((g for g in recommender.games_data if g['id'] == interaction['game_id']), None)
        if game_info:
            # Ph√¢n t√≠ch genres
            for genre in game_info.get('genre', []):
                if genre not in game_types:
                    game_types[genre] = 0
                game_types[genre] += 1
            
            # Ph√¢n t√≠ch platforms
            for platform in game_info.get('platform', []):
                if platform not in platforms:
                    platforms[platform] = 0
                platforms[platform] += 1
            
            # Ph√¢n t√≠ch publishers
            publisher = game_info.get('publisher', 'Unknown')
            if publisher not in publishers:
                publishers[publisher] = 0
            publishers[publisher] += 1
            
            # Ph√¢n t√≠ch release year
            release_date = game_info.get('release_date', '2020-01-01')
            if release_date:
                try:
                    release_year = int(release_date.split('-')[0])
                    release_dates.append(release_year)
                except:
                    release_dates.append(2020)
            
            # Ph√¢n t√≠ch price
            price = game_info.get('price', 0)
            price_ranges.append(price)
    
    user_data['behavior_patterns']['preferred_genres'] = game_types
    user_data['behavior_patterns']['preferred_platforms'] = platforms
    user_data['behavior_patterns']['preferred_publishers'] = publishers
    
    # Ph√¢n t√≠ch release year preferences
    if release_dates:
        current_year = datetime.now().year
        recent_years = [year for year in release_dates if year >= current_year - 2]
        user_data['behavior_patterns']['prefers_new_games'] = len(recent_years) / len(release_dates) > 0.5
        user_data['behavior_patterns']['avg_release_year'] = sum(release_dates) / len(release_dates)
    else:
        user_data['behavior_patterns']['prefers_new_games'] = False
        user_data['behavior_patterns']['avg_release_year'] = 2020
    
    # Ph√¢n t√≠ch price preferences
    if price_ranges:
        avg_price = sum(price_ranges) / len(price_ranges)
        user_data['behavior_patterns']['avg_price'] = avg_price
        user_data['behavior_patterns']['price_tolerance'] = {
            'low': avg_price < 500000,      # < 500k
            'medium': 500000 <= avg_price < 1500000,  # 500k - 1.5M
            'high': avg_price >= 1500000   # > 1.5M
        }
    else:
        user_data['behavior_patterns']['avg_price'] = 0
        user_data['behavior_patterns']['price_tolerance'] = {'medium': True}
    
    # Ph√¢n t√≠ch t∆∞∆°ng t√°c v·ªõi game ngo√†i top 10
    # L·∫•y top 10 games ph·ªï bi·∫øn nh·∫•t (d·ª±a tr√™n downloads)
    try:
        with open('game.json', 'r', encoding='utf-8') as f:
            all_games = json.load(f)
        
        # S·∫Øp x·∫øp games theo downloads (gi·∫£m d·∫ßn)
        sorted_games = sorted(all_games, key=lambda x: x.get('downloads', 0), reverse=True)
        top_10_game_ids = [game['id'] for game in sorted_games[:10]]
        
        # ƒê·∫øm t∆∞∆°ng t√°c v·ªõi game ngo√†i top 10
        interactions_outside_top10 = 0
        total_interactions = len(interactions)
        
        for interaction in interactions:
            game_id = interaction['game_id']
            if game_id not in top_10_game_ids:
                interactions_outside_top10 += 1
        
        # T√≠nh t·ª∑ l·ªá t∆∞∆°ng t√°c ngo√†i top 10
        if total_interactions > 0:
            outside_top10_ratio = interactions_outside_top10 / total_interactions
            user_data['behavior_patterns']['outside_top10_ratio'] = outside_top10_ratio
            user_data['behavior_patterns']['prefers_niche_games'] = outside_top10_ratio > 0.6  # > 60% t∆∞∆°ng t√°c ngo√†i top 10
        else:
            user_data['behavior_patterns']['outside_top10_ratio'] = 0.0
            user_data['behavior_patterns']['prefers_niche_games'] = False
            
    except Exception as e:
        print(f"Warning: Could not analyze top 10 games: {e}")
        user_data['behavior_patterns']['outside_top10_ratio'] = 0.0
        user_data['behavior_patterns']['prefers_niche_games'] = False
    
    # Ph√¢n t√≠ch m·ª©c ƒë·ªô t∆∞∆°ng t√°c
    view_count = len([i for i in interactions if i['type'] == 'view'])
    like_count = len([i for i in interactions if i['type'] == 'like'])
    purchase_count = len([i for i in interactions if i['type'] == 'purchase'])
    
    user_data['behavior_patterns']['engagement_level'] = {
        'views': view_count,
        'likes': like_count,
        'purchases': purchase_count,
        'total': len(interactions)
    }
    
    # T√≠nh engagement score (0-1)
    total_interactions = len(interactions)
    if total_interactions > 0:
        engagement_score = (like_count * 2 + purchase_count * 3) / (total_interactions * 3)
        user_data['behavior_patterns']['engagement_score'] = min(engagement_score, 1.0)
    else:
        user_data['behavior_patterns']['engagement_score'] = 0.0
    
    # Ph√¢n t√≠ch conversion rate (view -> like -> purchase)
    if view_count > 0:
        like_conversion = like_count / view_count
        user_data['behavior_patterns']['like_conversion_rate'] = like_conversion
    else:
        user_data['behavior_patterns']['like_conversion_rate'] = 0.0
    
    if like_count > 0:
        purchase_conversion = purchase_count / like_count
        user_data['behavior_patterns']['purchase_conversion_rate'] = purchase_conversion
    else:
        user_data['behavior_patterns']['purchase_conversion_rate'] = 0.0
    
    # Ph√¢n t√≠ch session patterns
    session_interactions = {}
    for interaction in interactions:
        session_id = interaction.get('session_id', 'unknown')
        if session_id not in session_interactions:
            session_interactions[session_id] = []
        session_interactions[session_id].append(interaction)
    
    user_data['behavior_patterns']['session_patterns'] = {
        'total_sessions': len(session_interactions),
        'avg_interactions_per_session': total_interactions / len(session_interactions) if session_interactions else 0,
        'longest_session': max([len(session) for session in session_interactions.values()]) if session_interactions else 0
    }
    
    # L∆∞u behavior patterns v√†o database
    save_behavior_patterns_to_db(user_id, user_data['behavior_patterns'])

def save_behavior_patterns_to_db(user_id, behavior_patterns):
    """L∆∞u behavior patterns v√†o database"""
    try:
        conn = sqlite3.connect('user_interactions.db')
        cursor = conn.cursor()
        
        # Chu·∫©n b·ªã d·ªØ li·ªáu
        preferred_genres = json.dumps(behavior_patterns.get('preferred_genres', {}))
        avg_price_range = f"{behavior_patterns.get('avg_price', 0):.0f}"
        prefers_new_games = 1 if behavior_patterns.get('prefers_new_games', False) else 0
        engagement_score = behavior_patterns.get('engagement_score', 0.0)
        pattern_data = json.dumps(behavior_patterns)
        
        # Insert or update behavior patterns
        cursor.execute('''
            INSERT OR REPLACE INTO user_behavior_patterns 
            (user_id, preferred_genres, avg_price_range, prefers_new_games, 
             engagement_score, last_analyzed, pattern_data)
            VALUES (?, ?, ?, ?, ?, datetime('now'), ?)
        ''', [user_id, preferred_genres, avg_price_range, prefers_new_games, 
              engagement_score, pattern_data])
        
        conn.commit()
        conn.close()
        
        print(f"‚úÖ Saved behavior patterns for user {user_id}")
        
    except Exception as e:
        print(f"‚ùå Error saving behavior patterns: {e}")

# ===== GLOBAL WEIGHT CONFIGURATIONS =====
# C√°c bi·∫øn to√†n c·ª•c ƒë·ªÉ d·ªÖ qu·∫£n l√Ω v√† thay ƒë·ªïi tr·ªçng s·ªë

# Tr·ªçng s·ªë khi KH√îNG c√≥ keyword
DEFAULT_SVD_WEIGHT_NO_KEYWORD = 0.45        # 45% SVD
DEFAULT_CONTENT_WEIGHT_NO_KEYWORD = 0.35    # 35% Content-based
DEFAULT_DEMOGRAPHIC_WEIGHT_NO_KEYWORD = 0.20 # 20% Demographic
DEFAULT_KEYWORD_WEIGHT_NO_KEYWORD = 0.0     # 0% Keyword

# Tr·ªçng s·ªë khi C√ì keyword
DEFAULT_SVD_WEIGHT_WITH_KEYWORD = 0.15      # 15% SVD
DEFAULT_CONTENT_WEIGHT_WITH_KEYWORD = 0.15  # 15% Content-based
DEFAULT_DEMOGRAPHIC_WEIGHT_WITH_KEYWORD = 0.10 # 10% Demographic
DEFAULT_KEYWORD_WEIGHT_WITH_KEYWORD = 0.60  # 60% Keyword

def get_dynamic_weights(user_id, keyword=None):
    """T√≠nh tr·ªçng s·ªë ƒë·ªông d·ª±a tr√™n behavior patterns v√† keyword"""
    # Ki·ªÉm tra c√≥ keyword kh√¥ng
    has_keyword = keyword and keyword.strip()
    
    if user_id not in learning_data:
        # Tr·ªçng s·ªë m·∫∑c ƒë·ªãnh - TH·ªêNG NH·∫§T v·ªõi game_recommendation_system.py
        if has_keyword:
            return {
                'svd': DEFAULT_SVD_WEIGHT_WITH_KEYWORD,        # 15%
                'content': DEFAULT_CONTENT_WEIGHT_WITH_KEYWORD,    # 15%
                'demographic': DEFAULT_DEMOGRAPHIC_WEIGHT_WITH_KEYWORD, # 10%
                'keyword': DEFAULT_KEYWORD_WEIGHT_WITH_KEYWORD     # 60%
            }
        else:
            return {
                'svd': DEFAULT_SVD_WEIGHT_NO_KEYWORD,        # 45%
                'content': DEFAULT_CONTENT_WEIGHT_NO_KEYWORD,    # 35%
                'demographic': DEFAULT_DEMOGRAPHIC_WEIGHT_NO_KEYWORD, # 20%
                'keyword': DEFAULT_KEYWORD_WEIGHT_NO_KEYWORD      # 0%
            }
    
    user_data = learning_data[user_id]
    behavior = user_data.get('behavior_patterns', {})
    
    # Tr·ªçng s·ªë c∆° b·∫£n d·ª±a tr√™n keyword - S·ª¨ D·ª§NG BI·∫æN TO√ÄN C·ª§C
    if has_keyword:
        weights = {
            'svd': DEFAULT_SVD_WEIGHT_WITH_KEYWORD,        # 15%
            'content': DEFAULT_CONTENT_WEIGHT_WITH_KEYWORD,    # 15%
            'demographic': DEFAULT_DEMOGRAPHIC_WEIGHT_WITH_KEYWORD, # 10%
            'keyword': DEFAULT_KEYWORD_WEIGHT_WITH_KEYWORD     # 60%
        }
    else:
        weights = {
            'svd': DEFAULT_SVD_WEIGHT_NO_KEYWORD,        # 45%
            'content': DEFAULT_CONTENT_WEIGHT_NO_KEYWORD,    # 35%
            'demographic': DEFAULT_DEMOGRAPHIC_WEIGHT_NO_KEYWORD, # 20%
            'keyword': DEFAULT_KEYWORD_WEIGHT_NO_KEYWORD      # 0%
        }
    
    # ƒêi·ªÅu ch·ªânh d·ª±a tr√™n behavior patterns
    
    # 1. N·∫øu user th√≠ch games m·ªõi ‚Üí TƒÉng content weight (d·ª±a tr√™n attributes)
    if behavior.get('prefers_new_games', False):
        if has_keyword:
            weights['content'] += 0.05
            weights['svd'] -= 0.03
            weights['demographic'] -= 0.02
        else:
            weights['content'] += 0.1
            weights['svd'] -= 0.05
            weights['demographic'] -= 0.05
    
    # 2. N·∫øu user c√≥ nhi·ªÅu t∆∞∆°ng t√°c ‚Üí TƒÉng SVD weight (collaborative filtering)
    engagement = behavior.get('engagement_level', {})
    total_interactions = engagement.get('total', 0)
    engagement_score = behavior.get('engagement_score', 0.0)
    
    if total_interactions > 10:  # User c√≥ nhi·ªÅu t∆∞∆°ng t√°c
        if has_keyword:
            weights['svd'] += 0.05
            weights['content'] -= 0.03
            weights['demographic'] -= 0.02
        else:
            weights['svd'] += 0.1
            weights['content'] -= 0.05
            weights['demographic'] -= 0.05
    
    # 3. N·∫øu user c√≥ engagement score cao ‚Üí TƒÉng SVD weight
    if engagement_score > 0.5:  # User c√≥ t·ª∑ l·ªá like/purchase cao
        if has_keyword:
            weights['svd'] += 0.03
            weights['content'] -= 0.02
            weights['demographic'] -= 0.01
        else:
            weights['svd'] += 0.05
            weights['content'] -= 0.03
            weights['demographic'] -= 0.02
    
    # 4. N·∫øu user c√≥ genre preferences r√µ r√†ng ‚Üí TƒÉng content weight
    preferred_genres = behavior.get('preferred_genres', {})
    if len(preferred_genres) > 0:
        max_genre_count = max(preferred_genres.values()) if preferred_genres else 0
        if max_genre_count >= 3:  # User c√≥ genre preference r√µ r√†ng
            if has_keyword:
                weights['content'] += 0.03
                weights['svd'] -= 0.02
                weights['demographic'] -= 0.01
            else:
                weights['content'] += 0.05
                weights['svd'] -= 0.03
                weights['demographic'] -= 0.02
    
    # 5. N·∫øu user active g·∫ßn ƒë√¢y ‚Üí TƒÉng content weight (preferences hi·ªán t·∫°i)
    if behavior.get('active_recently', False):
        if has_keyword:
            weights['content'] += 0.03
            weights['svd'] -= 0.02
            weights['demographic'] -= 0.01
        else:
            weights['content'] += 0.05
            weights['svd'] -= 0.03
            weights['demographic'] -= 0.02
    
    # 6. N·∫øu user c√≥ conversion rate cao ‚Üí TƒÉng SVD weight
    like_conversion = behavior.get('like_conversion_rate', 0.0)
    purchase_conversion = behavior.get('purchase_conversion_rate', 0.0)
    
    if like_conversion > 0.3:  # User c√≥ t·ª∑ l·ªá like cao
        if has_keyword:
            weights['svd'] += 0.02
            weights['content'] -= 0.01
            weights['demographic'] -= 0.01
        else:
            weights['svd'] += 0.03
            weights['content'] -= 0.02
            weights['demographic'] -= 0.01
    
    if purchase_conversion > 0.2:  # User c√≥ t·ª∑ l·ªá purchase cao
        if has_keyword:
            weights['svd'] += 0.03
            weights['content'] -= 0.02
            weights['demographic'] -= 0.01
        else:
            weights['svd'] += 0.05
            weights['content'] -= 0.03
            weights['demographic'] -= 0.02
    
    # 7. N·∫øu user c√≥ session patterns d√†i ‚Üí TƒÉng content weight
    session_patterns = behavior.get('session_patterns', {})
    avg_interactions_per_session = session_patterns.get('avg_interactions_per_session', 0)
    
    if avg_interactions_per_session > 5:  # User c√≥ session d√†i
        if has_keyword:
            weights['content'] += 0.02
            weights['svd'] -= 0.01
            weights['demographic'] -= 0.01
        else:
            weights['content'] += 0.03
            weights['svd'] -= 0.02
            weights['demographic'] -= 0.01
    
    # 8. N·∫øu user th∆∞·ªùng xuy√™n t∆∞∆°ng t√°c v·ªõi game ngo√†i top 10 ‚Üí Gi·∫£m keyword weight
    # (Keyword prediction kh√¥ng ch√≠nh x√°c, c·∫ßn gi·∫£m tr·ªçng s·ªë ƒë·ªÉ c√°c thu·∫≠t to√°n kh√°c g·ª£i √Ω t·ªët h∆°n)
    outside_top10_ratio = behavior.get('outside_top10_ratio', 0.0)
    prefers_niche_games = behavior.get('prefers_niche_games', False)
    
    if prefers_niche_games and outside_top10_ratio > 0.6:  # > 60% t∆∞∆°ng t√°c ngo√†i top 10
        if has_keyword:
            # Keyword prediction kh√¥ng ch√≠nh x√°c ‚Üí Gi·∫£m keyword weight, tƒÉng SVD v√† content
            weights['keyword'] -= 0.10  # Gi·∫£m keyword t·ª´ 60% xu·ªëng 50%
            weights['svd'] += 0.05      # TƒÉng SVD t·ª´ 15% l√™n 20%
            weights['content'] += 0.05  # TƒÉng content t·ª´ 15% l√™n 20%
            # demographic gi·ªØ nguy√™n 10%
        else:
            # Kh√¥ng c√≥ keyword, tƒÉng SVD v√† content ƒë·ªÉ g·ª£i √Ω t·ªët h∆°n
            weights['svd'] += 0.05      # TƒÉng SVD t·ª´ 45% l√™n 50%
            weights['content'] += 0.05  # TƒÉng content t·ª´ 35% l√™n 40%
            weights['demographic'] -= 0.10  # Gi·∫£m demographic t·ª´ 20% xu·ªëng 10%
    
    elif outside_top10_ratio > 0.4:  # 40-60% t∆∞∆°ng t√°c ngo√†i top 10 (m·ª©c ƒë·ªô v·ª´a ph·∫£i)
        if has_keyword:
            # Keyword prediction k√©m ch√≠nh x√°c ‚Üí Gi·∫£m keyword weight nh·∫π
            weights['keyword'] -= 0.05  # Gi·∫£m keyword t·ª´ 60% xu·ªëng 55%
            weights['svd'] += 0.03      # TƒÉng SVD t·ª´ 15% l√™n 18%
            weights['content'] += 0.02  # TƒÉng content t·ª´ 15% l√™n 17%
        else:
            # TƒÉng SVD v√† content nh·∫π ƒë·ªÉ c·∫£i thi·ªán g·ª£i √Ω
            weights['svd'] += 0.03      # TƒÉng SVD t·ª´ 45% l√™n 48%
            weights['content'] += 0.02  # TƒÉng content t·ª´ 35% l√™n 37%
            weights['demographic'] -= 0.05  # Gi·∫£m demographic t·ª´ 20% xu·ªëng 15%
    
    # ƒê·∫£m b·∫£o t·ªïng = 1.0
    total = sum(weights.values())
    for key in weights:
        weights[key] = weights[key] / total
    
    return weights

def check_and_retrain_svd(user_id):
    """Ki·ªÉm tra v√† retrain SVD model n·∫øu c·∫ßn thi·∫øt"""
    global recommender
    
    if user_id not in learning_data:
        return
    
    user_data = learning_data[user_id]
    interactions = user_data['interaction_history']
    
    # Ch·ªâ retrain n·∫øu c√≥ ƒë·ªß d·ªØ li·ªáu
    if len(interactions) < 10:  # C·∫ßn √≠t nh·∫•t 10 t∆∞∆°ng t√°c
        return
    
    # Ki·ªÉm tra xem c√≥ c·∫ßn retrain kh√¥ng (m·ªói 50 t∆∞∆°ng t√°c m·ªõi)
    last_retrain = user_data.get('last_retrain_count', 0)
    current_count = len(interactions)
    
    if current_count - last_retrain >= 50:  # Retrain m·ªói 50 t∆∞∆°ng t√°c m·ªõi
        print(f"üîÑ Auto-retraining SVD model for user {user_id}...")
        
        try:
            # Retrain SVD model
            recommender.retrain_svd_model()
            
            # C·∫≠p nh·∫≠t last retrain count
            user_data['last_retrain_count'] = current_count
            
            # Log retraining event
            log_retraining_event(user_id, current_count)
            
            print(f"‚úÖ SVD model retrained for user {user_id}")
            
        except Exception as e:
            print(f"‚ùå Error retraining SVD model: {e}")

def log_retraining_event(user_id, interactions_count):
    """Log retraining event v√†o database"""
    try:
        conn = sqlite3.connect('user_interactions.db')
        cursor = conn.cursor()
        
        cursor.execute('''
            INSERT INTO ai_training_log 
            (user_id, training_type, interactions_count, timestamp, notes)
            VALUES (?, ?, ?, datetime('now'), ?)
        ''', [user_id, 'auto_retrain', interactions_count, f'Auto-retrained after {interactions_count} interactions'])
        
        conn.commit()
        conn.close()
        
        print(f"‚úÖ Logged retraining event for user {user_id}")
        
    except Exception as e:
        print(f"‚ùå Error logging retraining event: {e}")

def get_system_health():
    """Ki·ªÉm tra t√¨nh tr·∫°ng h·ªá th·ªëng AI"""
    try:
        conn = sqlite3.connect('user_interactions.db')
        cursor = conn.cursor()
        
        # L·∫•y th·ªëng k√™ t·ªïng quan
        cursor.execute('SELECT COUNT(*) FROM user_interactions')
        total_interactions = cursor.fetchone()[0]
        
        cursor.execute('SELECT COUNT(DISTINCT user_id) FROM user_interactions')
        total_users = cursor.fetchone()[0]
        
        cursor.execute('SELECT COUNT(*) FROM user_behavior_patterns')
        users_with_behavior = cursor.fetchone()[0]
        
        cursor.execute('SELECT COUNT(*) FROM ai_training_log')
        total_retrains = cursor.fetchone()[0]
        
        # L·∫•y retrain g·∫ßn nh·∫•t
        cursor.execute('''
            SELECT timestamp, interactions_count, notes 
            FROM ai_training_log 
            ORDER BY timestamp DESC 
            LIMIT 1
        ''')
        last_retrain = cursor.fetchone()
        
        conn.close()
        
        return {
            'total_interactions': total_interactions,
            'total_users': total_users,
            'users_with_behavior': users_with_behavior,
            'total_retrains': total_retrains,
            'last_retrain': last_retrain,
            'system_status': 'healthy' if total_interactions > 0 else 'no_data'
        }
        
    except Exception as e:
        print(f"‚ùå Error getting system health: {e}")
        return {
            'system_status': 'error',
            'error': str(e)
        }
    
    # Ch·ªâ retrain n·∫øu c√≥ ƒë·ªß d·ªØ li·ªáu m·ªõi (√≠t nh·∫•t 5 t∆∞∆°ng t√°c m·ªõi)
    if len(interactions) < 5:
        return
    
    # Ki·ªÉm tra xem c√≥ c·∫ßn retrain kh√¥ng (m·ªói 10 t∆∞∆°ng t√°c)
    if len(interactions) % 10 == 0:
        print(f"üîÑ Retraining SVD model for user {user_id}...")
        
        # C·∫≠p nh·∫≠t user-item matrix v·ªõi d·ªØ li·ªáu m·ªõi
        try:
            # L·∫•y recommender instance
            global recommender
            if recommender:
                # C·∫≠p nh·∫≠t user data trong recommender
                for user in recommender.users_data:
                    if user['id'] == user_id:
                        # C·∫≠p nh·∫≠t favorite_games, purchased_games t·ª´ learning_data
                        user['favorite_games'] = learning_data[user_id]['preferences'].get('liked_games', [])
                        user['purchased_games'] = learning_data[user_id]['preferences'].get('purchased_games', [])
                        break
                
                # Retrain SVD model
                recommender.preprocess_data()
                recommender.train_svd_model()
                print(f"‚úÖ SVD model retrained successfully for user {user_id}")
                
                # Ghi log retrain v√†o file v·ªõi tham s·ªë model
                log_retrain_info(user_id, interactions, recommender)
                
        except Exception as e:
            print(f"‚ùå Error retraining SVD model: {e}")
            log_retrain_error(user_id, str(e))

def log_retrain_info(user_id, interactions, recommender=None):
    """Ghi th√¥ng tin retrain v√†o file log"""
    try:
        from datetime import datetime
        import json
        import numpy as np
        
        # T·∫°o th√¥ng tin retrain
        retrain_info = {
            'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
            'user_id': user_id,
            'total_interactions': len(interactions),
            'interaction_types': {},
            'recent_interactions': [],
            'behavior_patterns': learning_data.get(user_id, {}).get('behavior_patterns', {}),
            'preferences': learning_data.get(user_id, {}).get('preferences', {}),
            'model_parameters': {}
        }
        
        # ƒê·∫øm lo·∫°i t∆∞∆°ng t√°c
        for interaction in interactions:
            interaction_type = interaction.get('type', 'unknown')
            if interaction_type not in retrain_info['interaction_types']:
                retrain_info['interaction_types'][interaction_type] = 0
            retrain_info['interaction_types'][interaction_type] += 1
        
        # L·∫•y 5 t∆∞∆°ng t√°c g·∫ßn nh·∫•t
        recent_interactions = sorted(interactions, key=lambda x: x.get('timestamp', datetime.now()), reverse=True)[:5]
        for interaction in recent_interactions:
            retrain_info['recent_interactions'].append({
                'game_id': interaction.get('game_id'),
                'type': interaction.get('type'),
                'rating': interaction.get('rating'),
                'timestamp': interaction.get('timestamp').strftime('%Y-%m-%d %H:%M:%S') if interaction.get('timestamp') else 'N/A'
            })
        
        # Ghi tham s·ªë model n·∫øu c√≥ recommender
        if recommender:
            try:
                # SVD model parameters
                if hasattr(recommender, 'svd_model') and recommender.svd_model is not None:
                    if isinstance(recommender.svd_model, dict):
                        # SVD model l√† dict
                        retrain_info['model_parameters']['svd'] = {
                            'model_type': 'dict',
                            'keys': list(recommender.svd_model.keys()),
                            'size': len(recommender.svd_model)
                        }
                    else:
                        # SVD model l√† object
                        svd_params = {
                            'model_type': str(type(recommender.svd_model).__name__)
                        }
                        
                        # Th√™m c√°c thu·ªôc t√≠nh c√≥ s·∫µn
                        if hasattr(recommender.svd_model, 'n_factors'):
                            svd_params['n_factors'] = recommender.svd_model.n_factors
                        if hasattr(recommender.svd_model, 'n_epochs'):
                            svd_params['n_epochs'] = recommender.svd_model.n_epochs
                        if hasattr(recommender.svd_model, 'lr_all'):
                            svd_params['lr_all'] = recommender.svd_model.lr_all
                        if hasattr(recommender.svd_model, 'reg_all'):
                            svd_params['reg_all'] = recommender.svd_model.reg_all
                        
                        retrain_info['model_parameters']['svd'] = svd_params
                
                # User-Item matrix info
                if hasattr(recommender, 'user_item_matrix') and recommender.user_item_matrix is not None:
                    matrix = recommender.user_item_matrix
                    retrain_info['model_parameters']['user_item_matrix'] = {
                        'shape': list(matrix.shape),
                        'type': str(type(matrix).__name__)
                    }
                
                # Content similarity matrix info
                if hasattr(recommender, 'content_similarity_matrix') and recommender.content_similarity_matrix is not None:
                    retrain_info['model_parameters']['content_similarity'] = {
                        'shape': list(recommender.content_similarity_matrix.shape),
                        'type': str(type(recommender.content_similarity_matrix).__name__)
                    }
                
                # Dynamic weights for this user
                dynamic_weights = get_dynamic_weights(user_id)
                retrain_info['model_parameters']['dynamic_weights'] = dynamic_weights
                
                # User behavior analysis
                user_data = learning_data.get(user_id, {})
                behavior = user_data.get('behavior_patterns', {})
                retrain_info['model_parameters']['user_analysis'] = {
                    'engagement_level': behavior.get('engagement_level', {}),
                    'preferred_genres': behavior.get('preferred_genres', {}),
                    'prefers_new_games': behavior.get('prefers_new_games', False),
                    'active_recently': behavior.get('active_recently', False),
                    'avg_release_year': behavior.get('avg_release_year', 2020),
                    'avg_price': behavior.get('avg_price', 0)
                }
                
            except Exception as e:
                retrain_info['model_parameters']['error'] = f"Error extracting model parameters: {str(e)}"
        
        # Ghi v√†o file log (append mode)
        with open('ai_retrain_log.json', 'a', encoding='utf-8') as f:
            f.write(json.dumps(retrain_info, ensure_ascii=False, indent=2) + '\n')
        
        print(f"üìù Retrain log saved for user {user_id}")
        
    except Exception as e:
        print(f"‚ùå Error logging retrain info: {e}")

def log_retrain_error(user_id, error_message):
    """Ghi l·ªói retrain v√†o file log"""
    try:
        from datetime import datetime
        import json
        
        error_info = {
            'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
            'user_id': user_id,
            'error': error_message,
            'type': 'retrain_error'
        }
        
        # Ghi v√†o file log (append mode)
        with open('ai_retrain_log.json', 'a', encoding='utf-8') as f:
            f.write(json.dumps(error_info, ensure_ascii=False, indent=2) + '\n')
        
        print(f"üìù Error log saved for user {user_id}")
        
    except Exception as e:
        print(f"‚ùå Error logging retrain error: {e}")

def get_smart_recommendations(user_id, top_n=None, keyword=None):
    """L·∫•y recommendations th√¥ng minh d·ª±a tr√™n t∆∞∆°ng t√°c v√† keyword"""
    # S·ª≠ d·ª•ng tr·ª±c ti·∫øp get_hybrid_recommendations t·ª´ game_recommendation_system.py
    # H√†m n√†y ƒë√£ c√≥ s·∫µn logic x·ª≠ l√Ω keyword v√† tr·ªçng s·ªë ƒë·ªông
    # ‚è∞ S·ª¨ D·ª§NG 7 NG√ÄY G·∫¶N NH·∫§T ƒë·ªÉ analyze preferences
    basic_recs = recommender.get_hybrid_recommendations(
        user_id=user_id, 
        top_n=top_n, 
        keyword=keyword,
        enable_adaptive=True,    # B·∫≠t adaptive boosting
        recent_days=7            # Analyze t·ª´ 7 ng√†y g·∫ßn ƒë√¢y
    )
    
    # √Åp d·ª•ng learning t·ª´ t∆∞∆°ng t√°c
    if user_id in learning_data:
        user_data = learning_data[user_id]
        
        # Boost games theo preferred genres, release year, v√† price
        for rec in basic_recs:
            game_id = rec['game_id']
            game_info = next((g for g in recommender.games_data if g['id'] == game_id), None)
            
            if game_info:
                total_boost = 0
                
                # 1. Genre boost
                if 'preferred_genres' in user_data['behavior_patterns']:
                    preferred_genres = user_data['behavior_patterns']['preferred_genres']
                    game_genres = game_info.get('genre', [])
                    
                    genre_boost = 0
                    for genre in game_genres:
                        if genre in preferred_genres:
                            genre_boost += preferred_genres[genre] * 0.1
                    total_boost += genre_boost
                
                # 2. Release year boost (games m·ªõi)
                if user_data['behavior_patterns'].get('prefers_new_games', False):
                    current_year = datetime.now().year
                    release_date = game_info.get('release_date', '2020-01-01')
                    try:
                        game_year = int(release_date.split('-')[0]) if release_date else 2020
                    except:
                        game_year = 2020
                    if game_year >= current_year - 1:  # Games trong 1 nƒÉm g·∫ßn ƒë√¢y
                        year_boost = 0.15  # Boost cao cho games m·ªõi
                        total_boost += year_boost
                
                # 3. Price boost (theo price tolerance)
                price_tolerance = user_data['behavior_patterns'].get('price_tolerance', {})
                game_price = game_info.get('price', 0)
                
                if price_tolerance.get('low', False) and game_price < 500000:
                    total_boost += 0.1
                elif price_tolerance.get('medium', False) and 500000 <= game_price < 1500000:
                    total_boost += 0.1
                elif price_tolerance.get('high', False) and game_price >= 1500000:
                    total_boost += 0.1
                
                rec['hybrid_score'] += total_boost
        
        # Boost cho users ho·∫°t ƒë·ªông g·∫ßn ƒë√¢y
        if user_data['behavior_patterns'].get('active_recently', False):
            recent_boost = user_data['behavior_patterns'].get('recent_activity_score', 0) * 0.05
            for rec in basic_recs:
                rec['hybrid_score'] += recent_boost
    
    # S·∫Øp x·∫øp l·∫°i theo hybrid score (ƒë√£ ƒë∆∞·ª£c t√≠nh trong get_hybrid_recommendations)
    basic_recs.sort(key=lambda x: x['hybrid_score'], reverse=True)
    
    
    return basic_recs

@app.route('/')
def index():
    """Trang ch·ªß"""
    return render_template('index.html')

@app.route('/users')
def users():
    """Trang danh s√°ch users"""
    recommender = init_recommender()
    return render_template('users.html', users=recommender.users_data)

@app.route('/user/<int:user_id>')
def user_profile(user_id):
    """Trang profile user"""
    recommender = init_recommender()
    user_data = next((u for u in recommender.users_data if u['id'] == user_id), None)
    
    if not user_data:
        return "User kh√¥ng t·ªìn t·∫°i", 404
    
    # L·∫•y keyword t·ª´ query parameter v√† decode URL encoding
    keyword = request.args.get('keyword', '').strip()
    if keyword:
        from urllib.parse import unquote
        keyword = unquote(keyword)
    
    # L·∫•y interactions
    interactions = get_user_interactions(user_id)
    
    # L·∫•y smart recommendations - T·∫§T C·∫¢ games v·ªõi keyword
    recommendations = get_smart_recommendations(user_id, keyword=keyword)
    
    return render_template('user_profile.html', 
                         user=user_data, 
                         interactions=interactions,
                         recommendations=recommendations)

@app.route('/api/recommendations/<int:user_id>')
def api_recommendations(user_id):
    """API l·∫•y recommendations"""
    recommender = init_recommender()
    keyword = request.args.get('keyword', '').strip()
    if keyword:
        from urllib.parse import unquote
        keyword = unquote(keyword)
    recommendations = get_smart_recommendations(user_id, keyword=keyword)
    return jsonify(recommendations)

@app.route('/api/interact', methods=['POST'])
def api_interact():
    """API x·ª≠ l√Ω t∆∞∆°ng t√°c ng∆∞·ªùi d√πng"""
    data = request.json
    user_id = data.get('user_id')
    game_id = data.get('game_id')
    interaction_type = data.get('type')  # 'view', 'like', 'purchase', 'dislike'
    rating = data.get('rating')
    
    # L∆∞u t∆∞∆°ng t√°c
    save_user_interaction(user_id, game_id, interaction_type, rating)
    
    return jsonify({'status': 'success', 'message': 'T∆∞∆°ng t√°c ƒë√£ ƒë∆∞·ª£c l∆∞u'})

@app.route('/api/feedback', methods=['POST'])
def api_feedback():
    """API x·ª≠ l√Ω feedback"""
    data = request.json
    user_id = data.get('user_id')
    game_id = data.get('game_id')
    feedback_type = data.get('feedback_type')  # 'helpful', 'not_helpful'
    score = data.get('score')
    comment = data.get('comment')
    
    # L∆∞u feedback
    conn = sqlite3.connect('user_interactions.db')
    cursor = conn.cursor()
    
    cursor.execute('''
        INSERT INTO user_feedback (user_id, game_id, feedback_type, score, comment)
        VALUES (?, ?, ?, ?, ?)
    ''', (user_id, game_id, feedback_type, score, comment))
    
    conn.commit()
    conn.close()
    
    return jsonify({'status': 'success', 'message': 'Feedback ƒë√£ ƒë∆∞·ª£c l∆∞u'})

@app.route('/api/learning/<int:user_id>')
def api_learning_data(user_id):
    """API l·∫•y d·ªØ li·ªáu h·ªçc c·ªßa user"""
    if user_id in learning_data:
        return jsonify(learning_data[user_id])
    else:
        return jsonify({'message': 'Ch∆∞a c√≥ d·ªØ li·ªáu h·ªçc cho user n√†y'})

@app.route('/api/keyword-search/<int:user_id>')
def keyword_search(user_id):
    """API endpoint ƒë·ªÉ t√¨m ki·∫øm games theo keyword"""
    keyword = request.args.get('keyword', '').strip()
    if keyword:
        from urllib.parse import unquote
        keyword = unquote(keyword)
    keyword = keyword.lower()
    
    if not keyword:
        return jsonify({
            'success': False,
            'error': 'Keyword is required'
        })
    
    try:
        # L·∫•y t·∫•t c·∫£ games
        all_games = recommender.games_data
        
        # T√¨m games c√≥ keyword match
        keyword_results = []
        for game in all_games:
            # T√¨m ki·∫øm trong c√°c tr∆∞·ªùng text
            text_fields = []
            
            # Name
            if game.get('name'):
                text_fields.append(str(game['name']))
            
            # Genre (handle both list and string)
            genre = game.get('genre', [])
            if isinstance(genre, list):
                text_fields.append(' '.join(genre))
            else:
                text_fields.append(str(genre))
            
            # Description
            if game.get('description'):
                text_fields.append(str(game['description']))
            
            # Publisher
            if game.get('publisher'):
                text_fields.append(str(game['publisher']))
            
            # Platform (handle both list and string)
            platform = game.get('platform', [])
            if isinstance(platform, list):
                text_fields.append(' '.join(platform))
            else:
                text_fields.append(str(platform))
            
            # Mode
            if game.get('mode'):
                text_fields.append(str(game['mode']))
            
            # Multiplayer
            if game.get('multiplayer'):
                text_fields.append(str(game['multiplayer']))
            
            # Language
            if game.get('language'):
                text_fields.append(str(game['language']))
            
            # Ki·ªÉm tra keyword match
            text_content = ' '.join(text_fields).lower()
            
            # T√°ch keyword th√†nh c√°c t·ª´ ri√™ng bi·ªát
            keyword_words = keyword.split()
            
            # T√≠nh ƒëi·ªÉm cho t·ª´ng t·ª´ trong keyword
            total_score = 0
            for word in keyword_words:
                if word in text_content:
                    word_count = text_content.count(word)
                    word_score = min(word_count / len(text_content.split()) * 10, 1.0)
                    total_score += word_score
            
            # X·ª≠ l√Ω ƒë·∫∑c bi·ªát cho release_year
            try:
                import re
                release_date = game.get('release_date', '2020-01-01')
                try:
                    release_year = int(release_date.split('-')[0]) if release_date else 0
                except:
                    release_year = 0
                
                # T√¨m s·ªë nƒÉm trong keyword (c√≥ th·ªÉ l√† "2021", "iRacing 2021", "2021 game", etc.)
                year_pattern = r'\b(?:19|20)\d{2}\b'  # T√¨m nƒÉm 1900-2099 (non-capturing group)
                year_matches = re.findall(year_pattern, keyword.lower())
                
                if year_matches and release_year > 0:
                    # L·∫•y nƒÉm ƒë·∫ßu ti√™n t√¨m th·∫•y
                    keyword_year = int(year_matches[0])
                    
                    # N·∫øu keyword ch·ª©a nƒÉm v√† kh·ªõp v·ªõi release_year
                    if keyword_year == release_year:
                        total_score += 2.0  # Tr·ªçng s·ªë cao cho nƒÉm ch√≠nh x√°c
                    # N·∫øu keyword ch·ª©a nƒÉm g·∫ßn v·ªõi release_year (trong kho·∫£ng 2 nƒÉm)
                    elif abs(release_year - keyword_year) <= 2:
                        total_score += 1.0  # Tr·ªçng s·ªë th·∫•p h∆°n cho nƒÉm g·∫ßn
            except:
                pass
            
            # X·ª≠ l√Ω ƒë·∫∑c bi·ªát cho multiplayer
            if 'multiplayer' in keyword.lower():
                game_multiplayer = game.get('multiplayer', False)
                if game_multiplayer:
                    total_score += 1.0  # Tr·ªçng s·ªë cho multiplayer
            
            # Chia cho s·ªë t·ª´ ƒë·ªÉ c√≥ ƒëi·ªÉm trung b√¨nh
            if keyword_words:
                keyword_score = total_score / len(keyword_words)
            else:
                keyword_score = 0.0
            
            if keyword_score > 0:
                
                # L·∫•y th√¥ng tin game
                game_info = {
                    'game_id': game['id'],
                    'game_name': game['name'],
                    'keyword_score': keyword_score,
                    'hybrid_score': keyword_score,  # T·∫°m th·ªùi d√πng keyword_score
                    'svd_score': 0.0,
                    'content_score': 0.0,
                    'demographic_score': 0.0
                }
                
                keyword_results.append(game_info)
        
        # S·∫Øp x·∫øp theo keyword score
        keyword_results.sort(key=lambda x: x['keyword_score'], reverse=True)
        
        return jsonify({
            'success': True,
            'results': keyword_results,
            'keyword': keyword,
            'total_found': len(keyword_results)
        })
        
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e)
        })

if __name__ == '__main__':
    # Kh·ªüi t·∫°o database
    init_database()
    
    # Kh·ªüi t·∫°o recommender
    init_recommender()
    
    print("üåê Kh·ªüi ƒë·ªông Game Recommendation Web App...")
    print("üì± Truy c·∫≠p: http://localhost:5000")
    
    app.run(debug=True, host='0.0.0.0', port=5000)
